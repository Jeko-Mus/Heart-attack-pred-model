{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import pipeline      # Pipeline\n",
    "from sklearn import preprocessing # OrdinalEncoder, LabelEncoder\n",
    "from sklearn import impute\n",
    "from sklearn import compose\n",
    "from sklearn import model_selection # train_test_split\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn import set_config\n",
    "\n",
    "from sklearn.tree          import DecisionTreeClassifier\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.ensemble      import ExtraTreesClassifier\n",
    "from sklearn.ensemble      import AdaBoostClassifier\n",
    "from sklearn.ensemble      import GradientBoostingClassifier\n",
    "from xgboost               import XGBClassifier\n",
    "from lightgbm              import LGBMClassifier\n",
    "from catboost              import CatBoostClassifier\n",
    "from sklearn.linear_model  import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_heart = pd.read_csv('heart.csv')\n",
    "data_heart.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3585, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_saturation = pd.read_csv('o2Saturation.csv')\n",
    "data_saturation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_variables = ['age', 'sex', 'cp',\t'trtbps',\t'chol',\t'fbs', 'restecg',\t'thalachh',\t'exng',\t'oldpeak',\t'slp',\t'caa',\t'thall']\n",
    "y_variable  = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_heart[x_variables]\n",
    "y = data_heart[y_variable]\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# params_decision_tree = { 'kernel' : ['linear', 'rbf'],        'C': np.arange(1, 10, 1) }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_DecisionTree  = {'max_depth'   : [3, 4, 5, 6, 7, 8, 9]}\n",
    "param_ExtraTree     = {'n_estimators': [0.1, 1, 10, 100, 100, 1000],     'max_depth'     : [3, 4, 5, 6, 7, 8, 9]}\n",
    "param_RandomForest  = {'n_estimators': [0.1, 1, 10, 100, 100, 1000],     'max_depth'     : [3, 4, 5, 6, 7, 8, 9]}\n",
    "param_AdaBoost      = {'n_estimators': [0.1, 1, 10, 100, 100, 1000],     'learning_rate' : [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "param_SklGBM        = {'n_estimators': [0.1, 1, 10, 100, 100, 1000],     'learning_rate' : [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "param_XGBoost       = {'booster'     : ['gbtree', 'gblinear'],           'eta'           : [0.01, 0.1, 1, 10, 100, 1000] }\n",
    "param_LightGBM      = {'n_estimators': [0.01, 0.1, 1, 10, 100, 1000],    'learning_rate' : [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "param_LogisticRegr  = {'C'           : [0.01, 0.1, 1, 10, 100, 1000],    'max_iter'      : [10, 50, 100, 150, 200, 1000]}\n",
    "param_SVC           = {'kernel'      : ['linear', 'rbf'],                  'C'           : [0.01, 0.1, 1, 10, 100, 1000]}      # 'gamma'         : [0.001, 0.01, 0.1, 1, 10, 100, 1000] ,      \n",
    "\n",
    "\n",
    "grid_search_DecisionTree      = GridSearchCV(DecisionTreeClassifier(), param_DecisionTree, cv=5)\n",
    "grid_search_ExtraTree         = GridSearchCV(ExtraTreesClassifier(), param_ExtraTree, cv=5)\n",
    "grid_search_RandomForest      = GridSearchCV(RandomForestClassifier(), param_RandomForest, cv=5)\n",
    "grid_search_AdaBoost          = GridSearchCV(AdaBoostClassifier(), param_AdaBoost, cv=5)\n",
    "grid_search_SklGBM            = GridSearchCV(GradientBoostingClassifier(), param_SklGBM, cv=5)\n",
    "grid_search_XGBoost           = GridSearchCV(XGBClassifier(), param_XGBoost, cv=5)\n",
    "grid_search_LightGBM          = GridSearchCV(LGBMClassifier(), param_LightGBM, cv=5)\n",
    "grid_search_LogisticRegr      = GridSearchCV(LogisticRegression(), param_LogisticRegr, cv=5)\n",
    "grid_search_SVC               = GridSearchCV(SVC(), param_SVC, cv=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 210.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 131, in _validate_estimator\n",
      "    raise ValueError(\n",
      "ValueError: n_estimators must be an integer, got <class 'float'>.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.72328502 0.8284058  0.8284058  0.81980676 0.83285024\n",
      "        nan 0.75381643 0.82405797 0.8152657  0.83285024 0.84164251\n",
      "        nan 0.75845411 0.80193237 0.83719807 0.83729469 0.85043478\n",
      "        nan 0.74057971 0.80193237 0.84173913 0.83729469 0.84599034\n",
      "        nan 0.73130435 0.81082126 0.84589372 0.82415459 0.85043478\n",
      "        nan 0.75352657 0.81516908 0.83275362 0.8284058  0.84164251\n",
      "        nan 0.74869565 0.81980676 0.83719807 0.83719807 0.8284058 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 210.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 131, in _validate_estimator\n",
      "    raise ValueError(\n",
      "ValueError: n_estimators must be an integer, got <class 'float'>.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.70512077 0.79768116 0.83719807 0.8284058  0.82405797\n",
      "        nan 0.74898551 0.81536232 0.82405797 0.83729469 0.83294686\n",
      "        nan 0.67835749 0.81545894 0.81980676 0.82405797 0.82850242\n",
      "        nan 0.71439614 0.82850242 0.82405797 0.83729469 0.82859903\n",
      "        nan 0.73198068 0.80231884 0.83304348 0.83294686 0.81536232\n",
      "        nan 0.70985507 0.82       0.81990338 0.82415459 0.82859903\n",
      "        nan 0.71449275 0.77574879 0.80676329 0.82415459 0.81990338]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 0, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 0, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 0, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 0, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 0, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 0, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 0, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 0, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:606: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight *= np.exp(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486: UserWarning: Sample weights have reached infinite values, at iteration 1, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 486, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 132, in fit\n",
      "    self._validate_estimator()\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 490, in _validate_estimator\n",
      "    super()._validate_estimator(default=DecisionTreeClassifier(max_depth=1))\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 131, in _validate_estimator\n",
      "    raise ValueError(\n",
      "ValueError: n_estimators must be an integer, got <class 'float'>.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.68714976 0.67845411 0.77961353 0.77961353 0.82386473\n",
      "        nan 0.68714976 0.78830918 0.82386473 0.82386473 0.78917874\n",
      "        nan 0.68714976 0.81951691 0.74067633 0.74067633 0.73603865\n",
      "        nan 0.68714976 0.31285024 0.31285024 0.31285024 0.31285024\n",
      "        nan 0.68714976 0.31285024 0.31285024 0.31285024 0.31285024\n",
      "        nan 0.68714976 0.54193237 0.54193237 0.54193237 0.54193237]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 529, in fit\n",
      "    self._init_state()\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 374, in _init_state\n",
      "    self.estimators_ = np.empty((self.n_estimators, self.loss_.K), dtype=object)\n",
      "TypeError: 'float' object cannot be interpreted as an integer\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.5373913  0.71342995 0.79304348 0.79304348 0.7494686\n",
      "        nan 0.72241546 0.79294686 0.75816425 0.75816425 0.74937198\n",
      "        nan 0.75797101 0.76695652 0.7363285  0.7363285  0.74956522\n",
      "        nan 0.75797101 0.41024155 0.4057971  0.4057971  0.41024155\n",
      "        nan 0.75797101 0.41410628 0.40966184 0.40966184 0.40966184\n",
      "        nan 0.75797101 0.73188406 0.73188406 0.73188406 0.73188406]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:42:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\basic.py\", line 1538, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\basic.py\", line 1659, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Parameter num_iterations should be of type int, got \"0.01\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\basic.py\", line 1538, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\basic.py\", line 1659, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Parameter num_iterations should be of type int, got \"0.1\"\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5373913  0.68724638 0.8284058  0.7847343\n",
      "        nan        nan 0.70937198 0.83275362 0.78898551 0.77140097\n",
      "        nan        nan 0.73584541 0.78057971 0.78463768 0.77565217\n",
      "        nan        nan 0.71362319 0.6484058  0.6484058  0.6484058\n",
      "        nan        nan 0.69584541 0.67362319 0.67362319 0.67362319\n",
      "        nan        nan 0.69584541 0.69584541 0.69584541 0.69584541]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_DecisionTree.fit(X_train, y_train)\n",
    "grid_search_ExtraTree.fit(X_train, y_train)\n",
    "grid_search_RandomForest.fit(X_train, y_train)\n",
    "grid_search_AdaBoost.fit(X_train, y_train)\n",
    "grid_search_SklGBM.fit(X_train, y_train)\n",
    "grid_search_XGBoost.fit(X_train, y_train)\n",
    "grid_search_LightGBM.fit(X_train, y_train)\n",
    "grid_search_LogisticRegr.fit(X_train, y_train)\n",
    "grid_search_SVC.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree    =>    Best Score : 77.57    Best Parameters :   {'max_depth': 6}  \n",
      "Extra Trees      =>    Best Score : 85.04    Best Parameters :   {'max_depth': 5, 'n_estimators': 1000}  \n",
      "Random Forest    =>    Best Score : 83.73    Best Parameters :   {'max_depth': 4, 'n_estimators': 100}  \n",
      "AdaBoost         =>    Best Score : 82.39    Best Parameters :   {'learning_rate': 0.01, 'n_estimators': 1000}  \n",
      "Skl GBM          =>    Best Score : 79.3    Best Parameters :   {'learning_rate': 0.01, 'n_estimators': 100}  \n",
      "XGBoost          =>    Best Score : 82.85    Best Parameters :   {'booster': 'gblinear', 'eta': 0.1}  \n",
      "LightGBM         =>    Best Score : 83.28    Best Parameters :   {'learning_rate': 0.1, 'n_estimators': 10}  \n",
      "LogisticRegr     =>    Best Score : 82.85    Best Parameters :   {'C': 10, 'max_iter': 150}  \n",
      "SVC              =>    Best Score : 81.96    Best Parameters :   {'C': 0.1, 'kernel': 'linear'}  \n"
     ]
    }
   ],
   "source": [
    "print(f'Decision Tree    =>    Best Score : {round(grid_search_DecisionTree.best_score_ * 100, 2)}    Best Parameters :   {grid_search_DecisionTree.best_params_}  ')\n",
    "print(f'Extra Trees      =>    Best Score : {round(grid_search_ExtraTree.best_score_ * 100, 2)}    Best Parameters :   {grid_search_ExtraTree.best_params_}  ')\n",
    "print(f'Random Forest    =>    Best Score : {round(grid_search_RandomForest.best_score_ * 100, 2)}    Best Parameters :   {grid_search_RandomForest.best_params_}  ')\n",
    "print(f'AdaBoost         =>    Best Score : {round(grid_search_AdaBoost.best_score_ * 100, 2)}    Best Parameters :   {grid_search_AdaBoost.best_params_}  ')\n",
    "print(f'Skl GBM          =>    Best Score : {round(grid_search_SklGBM.best_score_ * 100, 2)}    Best Parameters :   {grid_search_SklGBM.best_params_}  ')\n",
    "print(f'XGBoost          =>    Best Score : {round(grid_search_XGBoost.best_score_ * 100, 2)}    Best Parameters :   {grid_search_XGBoost.best_params_}  ')\n",
    "print(f'LightGBM         =>    Best Score : {round(grid_search_LightGBM.best_score_ * 100, 2)}    Best Parameters :   {grid_search_LightGBM.best_params_}  ')\n",
    "print(f'LogisticRegr     =>    Best Score : {round(grid_search_LogisticRegr.best_score_ * 100, 2)}    Best Parameters :   {grid_search_LogisticRegr.best_params_}  ')\n",
    "print(f'SVC              =>    Best Score : {round(grid_search_SVC.best_score_ * 100, 2)}    Best Parameters :   {grid_search_SVC.best_params_}  ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nDecision Tree    =>    Best Score : 74.85    Best Parameters :   {'max_depth': 3}  \\nExtra Trees      =>    Best Score : 84.55    Best Parameters :   {'max_depth': 3, 'n_estimators': 10}  \\nRandom Forest    =>    Best Score : 82.79    Best Parameters :   {'max_depth': 4, 'n_estimators': 100}  \\nAdaBoost         =>    Best Score : 84.1     Best Parameters :   {'learning_rate': 0.01, 'n_estimators': 1000} \\nSkl GBM          =>    Best Score : 80.59    Best Parameters :   {'learning_rate': 1, 'n_estimators': 1000}  \\nXGBoost          =>    Best Score : 83.68    Best Parameters :   {'booster': 'gblinear', 'eta': 1}  \\nLightGBM         =>    Best Score : 81.47    Best Parameters :   {'learning_rate': 1, 'n_estimators': 10}\\n\\nLogisticRegr     =>    Best Score : 83.28    Best Parameters :   {'C': 0.1, 'max_iter': 200}  \\n\\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Decision Tree    =>    Best Score : 77.57    Best Parameters :   {'max_depth': 6}  \n",
    "Extra Trees      =>    Best Score : 85.04    Best Parameters :   {'max_depth': 5, 'n_estimators': 1000}  \n",
    "Random Forest    =>    Best Score : 83.73    Best Parameters :   {'max_depth': 4, 'n_estimators': 100}  \n",
    "AdaBoost         =>    Best Score : 82.39    Best Parameters :   {'learning_rate': 0.01, 'n_estimators': 1000}  \n",
    "Skl GBM          =>    Best Score : 79.30    Best Parameters :   {'learning_rate': 0.01, 'n_estimators': 100}  \n",
    "XGBoost          =>    Best Score : 82.85    Best Parameters :   {'booster': 'gblinear', 'eta': 0.1}  \n",
    "LightGBM         =>    Best Score : 83.28    Best Parameters :   {'learning_rate': 0.1, 'n_estimators': 10}  \n",
    "LogisticRegr     =>    Best Score : 82.85    Best Parameters :   {'C': 10, 'max_iter': 150}  \n",
    "SVC              =>    Best Score : 81.96    Best Parameters :   {'C': 0.1, 'kernel': 'linear'} \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   \"Decision Tree\":  DecisionTreeClassifier(max_depth=4, random_state=15),\n",
    "#   \"Extra Trees\":    ExtraTreesClassifier(n_estimators=100, random_state=15),\n",
    "#   \"Random Forest\":  RandomForestClassifier(n_estimators=100, random_state=15),\n",
    "#   \"AdaBoost\":       AdaBoostClassifier(n_estimators=100, random_state=15),\n",
    "#   \"Skl GBM\":        GradientBoostingClassifier(n_estimators=100, random_state=15),\n",
    "#   \"XGBoost\":        XGBClassifier(n_estimators=100, random_state=15),\n",
    "#   \"LightGBM\":       LGBMClassifier(n_estimators=100, random_state=15),\n",
    "#   \"CatBoost\":       CatBoostClassifier(n_estimators=100, random_state=15),\n",
    "#   'LogisticRegr':   LogisticRegression(random_state=15),\n",
    "#   'SVC' :           SVC(C=10, gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Decision Tree Train Accuracy :  ', round(tree.score(X_train, y_train) * 100, 2))\n",
    "# print('Decision Tree Test  Accuracy :  ', round(tree.score(X_test, y_test) * 100, 2))\n",
    "# print()\n",
    "# print('Random Forest Train Accuracy :  ', round(rand.score(X_train, y_train) * 100, 2))\n",
    "# print('Random Forest Test  Accuracy :  ', round(rand.score(X_test, y_test) * 100, 2))\n",
    "# print()\n",
    "# print('Logistic Regression Train Accuracy :  ', round(logic.score(X_train, y_train) * 100, 2))\n",
    "# print('Logistic Regression Test Accuracy :  ', round(logic.score(X_test, y_test) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_classifiers = {\n",
    "  \n",
    "#   \"Decision Tree\":  DecisionTreeClassifier(max_depth=4),\n",
    "#   \"Extra Trees\":    ExtraTreesClassifier(n_estimators=100),\n",
    "#   \"Random Forest\":  RandomForestClassifier(n_estimators=100),\n",
    "#   \"AdaBoost\":       AdaBoostClassifier(n_estimators=100),\n",
    "#   \"Skl GBM\":        GradientBoostingClassifier(n_estimators=100),\n",
    "#   \"XGBoost\":        XGBClassifier(n_estimators=100, random_state=15),\n",
    "#   \"LightGBM\":       LGBMClassifier(n_estimators=100, random_state=15),\n",
    "#   \"CatBoost\":       CatBoostClassifier(n_estimators=100, random_state=15),\n",
    "#   'LogisticRegr':   LogisticRegression(random_state=15),\n",
    "#   'SVC' :           SVC(C=10, gamma=0.001)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\n",
    "\n",
    "# results = pd.DataFrame({'Model': [], 'MSE': [], 'MAB': [], 'Time': []})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# for model_name, model in tree_classifiers.items():\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     model.fit(X_train, y_train)\n",
    "#     total_time = time.time() - start_time\n",
    "        \n",
    "#     pred = model.predict(X_test)\n",
    "    \n",
    "#     rang = abs(y_train.max()) - abs(y_train.min())\n",
    "\n",
    "#     results = results.append({\"Model\":          model_name,\n",
    "#                               \"MSE\":            metrics.mean_squared_error(y_test, pred),\n",
    "#                               \"MAB\":            metrics.mean_absolute_error(y_test, pred),\n",
    "#                               \" % error\":       metrics.mean_squared_error(y_test, pred) / rang,\n",
    "#                               \"Accuracy Score\": model.score(X_test,y_test),\n",
    "#                               \"Time\":           total_time},\n",
    "#                               ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dad25_row0_col1, #T_dad25_row0_col2 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,#5fba7d 0.1%, transparent 0.1%);\n",
       "}\n",
       "#T_dad25_row1_col1, #T_dad25_row1_col2, #T_dad25_row2_col1, #T_dad25_row2_col2, #T_dad25_row3_col1, #T_dad25_row3_col2, #T_dad25_row4_col1, #T_dad25_row4_col2, #T_dad25_row5_col1, #T_dad25_row5_col2, #T_dad25_row6_col1, #T_dad25_row6_col2, #T_dad25_row7_col1, #T_dad25_row7_col2, #T_dad25_row8_col1, #T_dad25_row8_col2 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,#5fba7d 0.2%, transparent 0.2%);\n",
       "}\n",
       "#T_dad25_row9_col1, #T_dad25_row9_col2 {\n",
       "  width: 10em;\n",
       "  height: 80%;\n",
       "  background: linear-gradient(90deg,#5fba7d 0.3%, transparent 0.3%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dad25_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th class=\"col_heading level0 col2\" >MAB</th>\n",
       "      <th class=\"col_heading level0 col3\" >Time</th>\n",
       "      <th class=\"col_heading level0 col4\" > % error</th>\n",
       "      <th class=\"col_heading level0 col5\" >Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dad25_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_dad25_row0_col0\" class=\"data row0 col0\" >LogisticRegr</td>\n",
       "      <td id=\"T_dad25_row0_col1\" class=\"data row0 col1\" >0.118421</td>\n",
       "      <td id=\"T_dad25_row0_col2\" class=\"data row0 col2\" >0.118421</td>\n",
       "      <td id=\"T_dad25_row0_col3\" class=\"data row0 col3\" >0.033905</td>\n",
       "      <td id=\"T_dad25_row0_col4\" class=\"data row0 col4\" >0.118421</td>\n",
       "      <td id=\"T_dad25_row0_col5\" class=\"data row0 col5\" >0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dad25_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_dad25_row1_col0\" class=\"data row1 col0\" >CatBoost</td>\n",
       "      <td id=\"T_dad25_row1_col1\" class=\"data row1 col1\" >0.157895</td>\n",
       "      <td id=\"T_dad25_row1_col2\" class=\"data row1 col2\" >0.157895</td>\n",
       "      <td id=\"T_dad25_row1_col3\" class=\"data row1 col3\" >0.370825</td>\n",
       "      <td id=\"T_dad25_row1_col4\" class=\"data row1 col4\" >0.157895</td>\n",
       "      <td id=\"T_dad25_row1_col5\" class=\"data row1 col5\" >0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dad25_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_dad25_row2_col0\" class=\"data row2 col0\" >Random Forest</td>\n",
       "      <td id=\"T_dad25_row2_col1\" class=\"data row2 col1\" >0.184211</td>\n",
       "      <td id=\"T_dad25_row2_col2\" class=\"data row2 col2\" >0.184211</td>\n",
       "      <td id=\"T_dad25_row2_col3\" class=\"data row2 col3\" >0.167991</td>\n",
       "      <td id=\"T_dad25_row2_col4\" class=\"data row2 col4\" >0.184211</td>\n",
       "      <td id=\"T_dad25_row2_col5\" class=\"data row2 col5\" >0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dad25_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_dad25_row3_col0\" class=\"data row3 col0\" >Skl GBM</td>\n",
       "      <td id=\"T_dad25_row3_col1\" class=\"data row3 col1\" >0.184211</td>\n",
       "      <td id=\"T_dad25_row3_col2\" class=\"data row3 col2\" >0.184211</td>\n",
       "      <td id=\"T_dad25_row3_col3\" class=\"data row3 col3\" >0.075965</td>\n",
       "      <td id=\"T_dad25_row3_col4\" class=\"data row3 col4\" >0.184211</td>\n",
       "      <td id=\"T_dad25_row3_col5\" class=\"data row3 col5\" >0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dad25_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_dad25_row4_col0\" class=\"data row4 col0\" >Extra Trees</td>\n",
       "      <td id=\"T_dad25_row4_col1\" class=\"data row4 col1\" >0.197368</td>\n",
       "      <td id=\"T_dad25_row4_col2\" class=\"data row4 col2\" >0.197368</td>\n",
       "      <td id=\"T_dad25_row4_col3\" class=\"data row4 col3\" >0.199117</td>\n",
       "      <td id=\"T_dad25_row4_col4\" class=\"data row4 col4\" >0.197368</td>\n",
       "      <td id=\"T_dad25_row4_col5\" class=\"data row4 col5\" >0.802632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dad25_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_dad25_row5_col0\" class=\"data row5 col0\" >LightGBM</td>\n",
       "      <td id=\"T_dad25_row5_col1\" class=\"data row5 col1\" >0.210526</td>\n",
       "      <td id=\"T_dad25_row5_col2\" class=\"data row5 col2\" >0.210526</td>\n",
       "      <td id=\"T_dad25_row5_col3\" class=\"data row5 col3\" >0.026059</td>\n",
       "      <td id=\"T_dad25_row5_col4\" class=\"data row5 col4\" >0.210526</td>\n",
       "      <td id=\"T_dad25_row5_col5\" class=\"data row5 col5\" >0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dad25_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_dad25_row6_col0\" class=\"data row6 col0\" >XGBoost</td>\n",
       "      <td id=\"T_dad25_row6_col1\" class=\"data row6 col1\" >0.236842</td>\n",
       "      <td id=\"T_dad25_row6_col2\" class=\"data row6 col2\" >0.236842</td>\n",
       "      <td id=\"T_dad25_row6_col3\" class=\"data row6 col3\" >0.058917</td>\n",
       "      <td id=\"T_dad25_row6_col4\" class=\"data row6 col4\" >0.236842</td>\n",
       "      <td id=\"T_dad25_row6_col5\" class=\"data row6 col5\" >0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dad25_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_dad25_row7_col0\" class=\"data row7 col0\" >Decision Tree</td>\n",
       "      <td id=\"T_dad25_row7_col1\" class=\"data row7 col1\" >0.250000</td>\n",
       "      <td id=\"T_dad25_row7_col2\" class=\"data row7 col2\" >0.250000</td>\n",
       "      <td id=\"T_dad25_row7_col3\" class=\"data row7 col3\" >0.006294</td>\n",
       "      <td id=\"T_dad25_row7_col4\" class=\"data row7 col4\" >0.250000</td>\n",
       "      <td id=\"T_dad25_row7_col5\" class=\"data row7 col5\" >0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dad25_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_dad25_row8_col0\" class=\"data row8 col0\" >AdaBoost</td>\n",
       "      <td id=\"T_dad25_row8_col1\" class=\"data row8 col1\" >0.250000</td>\n",
       "      <td id=\"T_dad25_row8_col2\" class=\"data row8 col2\" >0.250000</td>\n",
       "      <td id=\"T_dad25_row8_col3\" class=\"data row8 col3\" >0.144137</td>\n",
       "      <td id=\"T_dad25_row8_col4\" class=\"data row8 col4\" >0.250000</td>\n",
       "      <td id=\"T_dad25_row8_col5\" class=\"data row8 col5\" >0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dad25_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_dad25_row9_col0\" class=\"data row9 col0\" >SVC</td>\n",
       "      <td id=\"T_dad25_row9_col1\" class=\"data row9 col1\" >0.328947</td>\n",
       "      <td id=\"T_dad25_row9_col2\" class=\"data row9 col2\" >0.328947</td>\n",
       "      <td id=\"T_dad25_row9_col3\" class=\"data row9 col3\" >0.007979</td>\n",
       "      <td id=\"T_dad25_row9_col4\" class=\"data row9 col4\" >0.328947</td>\n",
       "      <td id=\"T_dad25_row9_col5\" class=\"data row9 col5\" >0.671053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d4900ad880>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results_ord = results.sort_values(by=['Accuracy Score'], ascending=False, ignore_index=True)\n",
    "# results_ord.index += 1 \n",
    "# results_ord.style.bar(subset=['MSE', 'MAB'], vmin=0, vmax=100, color='#5fba7d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Omistaja\\.conda\\envs\\pz\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:53:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate set to 0.045181\n",
      "0:\tlearn: 0.6814289\ttotal: 876us\tremaining: 86.7ms\n",
      "1:\tlearn: 0.6694359\ttotal: 1.65ms\tremaining: 80.8ms\n",
      "2:\tlearn: 0.6586929\ttotal: 2.31ms\tremaining: 74.5ms\n",
      "3:\tlearn: 0.6482036\ttotal: 2.97ms\tremaining: 71.3ms\n",
      "4:\tlearn: 0.6363458\ttotal: 3.71ms\tremaining: 70.6ms\n",
      "5:\tlearn: 0.6258679\ttotal: 4.49ms\tremaining: 70.4ms\n",
      "6:\tlearn: 0.6182697\ttotal: 5.19ms\tremaining: 68.9ms\n",
      "7:\tlearn: 0.6064209\ttotal: 5.97ms\tremaining: 68.6ms\n",
      "8:\tlearn: 0.5980383\ttotal: 6.72ms\tremaining: 67.9ms\n",
      "9:\tlearn: 0.5898914\ttotal: 7.46ms\tremaining: 67.1ms\n",
      "10:\tlearn: 0.5832363\ttotal: 8.2ms\tremaining: 66.3ms\n",
      "11:\tlearn: 0.5755464\ttotal: 9.02ms\tremaining: 66.2ms\n",
      "12:\tlearn: 0.5694149\ttotal: 9.94ms\tremaining: 66.5ms\n",
      "13:\tlearn: 0.5609318\ttotal: 10.8ms\tremaining: 66.6ms\n",
      "14:\tlearn: 0.5542274\ttotal: 12ms\tremaining: 68.2ms\n",
      "15:\tlearn: 0.5475904\ttotal: 14.5ms\tremaining: 76.1ms\n",
      "16:\tlearn: 0.5407990\ttotal: 15.6ms\tremaining: 76ms\n",
      "17:\tlearn: 0.5333670\ttotal: 16.6ms\tremaining: 75.8ms\n",
      "18:\tlearn: 0.5265536\ttotal: 17.7ms\tremaining: 75.4ms\n",
      "19:\tlearn: 0.5202105\ttotal: 18.6ms\tremaining: 74.4ms\n",
      "20:\tlearn: 0.5137304\ttotal: 19.4ms\tremaining: 72.9ms\n",
      "21:\tlearn: 0.5075368\ttotal: 20.3ms\tremaining: 71.9ms\n",
      "22:\tlearn: 0.5018622\ttotal: 21.2ms\tremaining: 70.9ms\n",
      "23:\tlearn: 0.4966143\ttotal: 22ms\tremaining: 69.7ms\n",
      "24:\tlearn: 0.4909033\ttotal: 23.1ms\tremaining: 69.4ms\n",
      "25:\tlearn: 0.4850933\ttotal: 24.5ms\tremaining: 69.7ms\n",
      "26:\tlearn: 0.4800317\ttotal: 25.8ms\tremaining: 69.7ms\n",
      "27:\tlearn: 0.4760542\ttotal: 26.5ms\tremaining: 68.1ms\n",
      "28:\tlearn: 0.4709449\ttotal: 27.4ms\tremaining: 67ms\n",
      "29:\tlearn: 0.4658743\ttotal: 28.2ms\tremaining: 65.7ms\n",
      "30:\tlearn: 0.4613182\ttotal: 29ms\tremaining: 64.5ms\n",
      "31:\tlearn: 0.4570831\ttotal: 29.8ms\tremaining: 63.4ms\n",
      "32:\tlearn: 0.4534896\ttotal: 30.6ms\tremaining: 62.1ms\n",
      "33:\tlearn: 0.4500919\ttotal: 32.3ms\tremaining: 62.8ms\n",
      "34:\tlearn: 0.4453911\ttotal: 32.8ms\tremaining: 60.9ms\n",
      "35:\tlearn: 0.4412649\ttotal: 33.6ms\tremaining: 59.8ms\n",
      "36:\tlearn: 0.4378842\ttotal: 34.5ms\tremaining: 58.7ms\n",
      "37:\tlearn: 0.4337203\ttotal: 35.3ms\tremaining: 57.7ms\n",
      "38:\tlearn: 0.4300189\ttotal: 37.7ms\tremaining: 59ms\n",
      "39:\tlearn: 0.4260419\ttotal: 39.2ms\tremaining: 58.8ms\n",
      "40:\tlearn: 0.4223859\ttotal: 40.1ms\tremaining: 57.7ms\n",
      "41:\tlearn: 0.4184101\ttotal: 40.9ms\tremaining: 56.5ms\n",
      "42:\tlearn: 0.4145414\ttotal: 41.8ms\tremaining: 55.4ms\n",
      "43:\tlearn: 0.4108015\ttotal: 42.6ms\tremaining: 54.2ms\n",
      "44:\tlearn: 0.4076606\ttotal: 43.3ms\tremaining: 52.9ms\n",
      "45:\tlearn: 0.4047506\ttotal: 44ms\tremaining: 51.7ms\n",
      "46:\tlearn: 0.4019294\ttotal: 44.8ms\tremaining: 50.5ms\n",
      "47:\tlearn: 0.3987004\ttotal: 45.5ms\tremaining: 49.3ms\n",
      "48:\tlearn: 0.3960742\ttotal: 46.2ms\tremaining: 48.1ms\n",
      "49:\tlearn: 0.3934322\ttotal: 47ms\tremaining: 47ms\n",
      "50:\tlearn: 0.3906482\ttotal: 47.7ms\tremaining: 45.8ms\n",
      "51:\tlearn: 0.3883060\ttotal: 48.4ms\tremaining: 44.7ms\n",
      "52:\tlearn: 0.3854132\ttotal: 49.1ms\tremaining: 43.6ms\n",
      "53:\tlearn: 0.3826290\ttotal: 50.6ms\tremaining: 43.1ms\n",
      "54:\tlearn: 0.3802554\ttotal: 51.5ms\tremaining: 42.1ms\n",
      "55:\tlearn: 0.3773832\ttotal: 53.3ms\tremaining: 41.9ms\n",
      "56:\tlearn: 0.3748688\ttotal: 54.2ms\tremaining: 40.9ms\n",
      "57:\tlearn: 0.3719113\ttotal: 54.7ms\tremaining: 39.6ms\n",
      "58:\tlearn: 0.3695729\ttotal: 55.6ms\tremaining: 38.6ms\n",
      "59:\tlearn: 0.3675929\ttotal: 56.4ms\tremaining: 37.6ms\n",
      "60:\tlearn: 0.3656493\ttotal: 57.1ms\tremaining: 36.5ms\n",
      "61:\tlearn: 0.3635322\ttotal: 57.9ms\tremaining: 35.5ms\n",
      "62:\tlearn: 0.3614090\ttotal: 58.7ms\tremaining: 34.5ms\n",
      "63:\tlearn: 0.3588555\ttotal: 59.6ms\tremaining: 33.5ms\n",
      "64:\tlearn: 0.3568828\ttotal: 60.6ms\tremaining: 32.6ms\n",
      "65:\tlearn: 0.3544874\ttotal: 61.6ms\tremaining: 31.7ms\n",
      "66:\tlearn: 0.3523686\ttotal: 63.2ms\tremaining: 31.1ms\n",
      "67:\tlearn: 0.3503940\ttotal: 64.2ms\tremaining: 30.2ms\n",
      "68:\tlearn: 0.3486311\ttotal: 65.3ms\tremaining: 29.3ms\n",
      "69:\tlearn: 0.3467981\ttotal: 66.4ms\tremaining: 28.4ms\n",
      "70:\tlearn: 0.3449542\ttotal: 67.2ms\tremaining: 27.5ms\n",
      "71:\tlearn: 0.3428665\ttotal: 68.1ms\tremaining: 26.5ms\n",
      "72:\tlearn: 0.3411425\ttotal: 69.5ms\tremaining: 25.7ms\n",
      "73:\tlearn: 0.3391488\ttotal: 70.5ms\tremaining: 24.8ms\n",
      "74:\tlearn: 0.3367147\ttotal: 71.7ms\tremaining: 23.9ms\n",
      "75:\tlearn: 0.3351116\ttotal: 73.7ms\tremaining: 23.3ms\n",
      "76:\tlearn: 0.3331587\ttotal: 74.8ms\tremaining: 22.4ms\n",
      "77:\tlearn: 0.3312505\ttotal: 75.6ms\tremaining: 21.3ms\n",
      "78:\tlearn: 0.3297378\ttotal: 76.3ms\tremaining: 20.3ms\n",
      "79:\tlearn: 0.3278986\ttotal: 77.2ms\tremaining: 19.3ms\n",
      "80:\tlearn: 0.3262464\ttotal: 78ms\tremaining: 18.3ms\n",
      "81:\tlearn: 0.3241845\ttotal: 78.8ms\tremaining: 17.3ms\n",
      "82:\tlearn: 0.3223295\ttotal: 79.7ms\tremaining: 16.3ms\n",
      "83:\tlearn: 0.3204819\ttotal: 81.4ms\tremaining: 15.5ms\n",
      "84:\tlearn: 0.3186853\ttotal: 82.2ms\tremaining: 14.5ms\n",
      "85:\tlearn: 0.3166727\ttotal: 82.9ms\tremaining: 13.5ms\n",
      "86:\tlearn: 0.3152862\ttotal: 83.6ms\tremaining: 12.5ms\n",
      "87:\tlearn: 0.3136317\ttotal: 84.3ms\tremaining: 11.5ms\n",
      "88:\tlearn: 0.3123114\ttotal: 85.2ms\tremaining: 10.5ms\n",
      "89:\tlearn: 0.3111481\ttotal: 86ms\tremaining: 9.55ms\n",
      "90:\tlearn: 0.3089279\ttotal: 87ms\tremaining: 8.61ms\n",
      "91:\tlearn: 0.3073945\ttotal: 88.4ms\tremaining: 7.68ms\n",
      "92:\tlearn: 0.3063174\ttotal: 89.2ms\tremaining: 6.71ms\n",
      "93:\tlearn: 0.3047970\ttotal: 89.9ms\tremaining: 5.74ms\n",
      "94:\tlearn: 0.3030295\ttotal: 90.6ms\tremaining: 4.77ms\n",
      "95:\tlearn: 0.3017720\ttotal: 91.3ms\tremaining: 3.8ms\n",
      "96:\tlearn: 0.2999158\ttotal: 91.9ms\tremaining: 2.84ms\n",
      "97:\tlearn: 0.2993076\ttotal: 92.5ms\tremaining: 1.89ms\n",
      "98:\tlearn: 0.2976850\ttotal: 93.2ms\tremaining: 940us\n",
      "99:\tlearn: 0.2961219\ttotal: 93.9ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1d4900dbca0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decision_tree  =    DecisionTreeClassifier(max_depth=4, random_state=15)\n",
    "# random_forest  =    RandomForestClassifier(n_estimators=100, random_state=15)\n",
    "# logistic       =    LogisticRegression(random_state=15)\n",
    "# extra_trees    =    ExtraTreesClassifier(n_estimators=100, random_state=15)\n",
    "# ada_boost      =    AdaBoostClassifier(n_estimators=100, random_state=15)\n",
    "# skl_GBM        =    GradientBoostingClassifier(n_estimators=100, random_state=15)\n",
    "# xG_Boost       =    XGBClassifier(n_estimators=100, random_state=15)\n",
    "# lightGBM       =    LGBMClassifier(n_estimators=100, random_state=15)\n",
    "# catBoost       =    CatBoostClassifier(n_estimators=100, random_state=15)\n",
    "\n",
    "# decision_tree.fit(X_train, y_train)\n",
    "# random_forest.fit(X_train, y_train)\n",
    "# logistic.fit(X_train, y_train)\n",
    "# extra_trees.fit(X_train, y_train)\n",
    "# ada_boost.fit(X_train, y_train)\n",
    "# skl_GBM.fit(X_train, y_train)\n",
    "# xG_Boost.fit(X_train, y_train)\n",
    "# lightGBM.fit(X_train, y_train)\n",
    "# catBoost.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE         : Train 87.67 :     Test : 75.0\n",
      "RANDOM FOREST         : Train 100.0 :     Test : 81.58\n",
      "LOGISTIC REGRESSION   : Train 85.46 :     Test : 88.16\n",
      "EXTRA TREES           : Train 100.0 :  Test : 80.26\n",
      "ADA BOOST             : Train 97.36 :    Test : 75.0\n",
      "SKL GBM               : Train 99.56 :      Test : 81.58\n",
      "XG BOOST              : Train 100.0 :     Test : 76.32\n",
      "LIGHT GBM             : Train 100.0 :     Test : 78.95\n",
      "CAT BOOST             : Train 92.95 :     Test : 84.21\n"
     ]
    }
   ],
   "source": [
    "# print(f'DECISION TREE         : Train {round(decision_tree.score(X_train, y_train) * 100, 2)} :     Test : {round(decision_tree.score(X_test, y_test) * 100, 2)}')\n",
    "# print(f'RANDOM FOREST         : Train {round(random_forest.score(X_train, y_train) * 100, 2)} :     Test : {round(random_forest.score(X_test, y_test) * 100, 2)}')\n",
    "# print(f'LOGISTIC REGRESSION   : Train {round(logistic.score(X_train, y_train) * 100, 2)} :     Test : {round(logistic.score(X_test, y_test) * 100, 2)}')\n",
    "# print(f'EXTRA TREES           : Train {round(extra_trees.score(X_train, y_train) * 100, 2)} :  Test : {round(extra_trees.score(X_test, y_test) * 100, 2)}')\n",
    "# print(f'ADA BOOST             : Train {round(ada_boost.score(X_train, y_train) * 100, 2)} :    Test : {round(ada_boost.score(X_test, y_test) * 100, 2)}')\n",
    "# print(f'SKL GBM               : Train {round(skl_GBM.score(X_train, y_train) * 100, 2)} :      Test : {round(skl_GBM.score(X_test, y_test) * 100, 2)}')\n",
    "# print(f'XG BOOST              : Train {round(xG_Boost.score(X_train, y_train) * 100, 2)} :     Test : {round(xG_Boost.score(X_test, y_test) * 100, 2)}')\n",
    "# print(f'LIGHT GBM             : Train {round(lightGBM.score(X_train, y_train) * 100, 2)} :     Test : {round(lightGBM.score(X_test, y_test) * 100, 2)}')\n",
    "# print(f'CAT BOOST             : Train {round(catBoost.score(X_train, y_train) * 100, 2)} :     Test : {round(catBoost.score(X_test, y_test) * 100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Accuracy_Default  Accuracy_HyperParameter  Accuracy_Enhanced\n",
      "0  Decision Tree              78.9                     80.3               85.5\n",
      "1    Extra Trees              81.6                     86.8               77.6\n",
      "2  Random Forest              85.5                     85.5               88.2\n",
      "3       AdaBoost              78.9                     86.8               86.8\n",
      "4        Skl GBM              78.9                     85.5               86.8\n",
      "5        XGBoost              85.5                     84.2               82.9\n",
      "6       LightGBM              82.9                     84.2               84.2\n",
      "7   LogisticRegr              82.9                     85.5               84.2\n",
      "8            SVC              71.1                     82.9               81.6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAILCAYAAAA5YpLCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABXmElEQVR4nO3dd7hU1fX/8feiKDZQFAlWUKMgXECaEUFRsSUaCxowiGIBC2DU6E/TFEvK1xh7omJsIQQIKmqqikKCnSIgirFiQSOIJVSlrN8fa891uN4L9yJz5s7l83qeeWbmnDMz+0w76+y99t7m7oiIiIhI4dUrdgFERERENhYKvEREREQyosBLREREJCMKvEREREQyosBLREREJCMKvEREREQyosBLRETWycx6mZmb2fCv+TwD0/MM3DAlEyktCrxEagkz+0k6ILmZ7VXs8khx5X0XVpvZ7mvZbmLetgMzLKKIrAcFXiK1gJkZcAaQG9F4UBGLI7XHSiD33fgKM/smcGDaTkRKgAIvkdrhMKAVcC/wIXCqmW1S3CJJLfAhMBU4zcwaVLL+TCIw+2umpRKR9abAS6R2yNVw3QGMArYDjqtqYzPbycxuMrPXzGy5mX1sZs+b2c/Wd9vUVDWpite7J61vmbesZVp2j5ntaWZjzWx+ahrrlbbpbGY3mtnM9LrLUzl+Y2bbrGX/+prZ43mPmWtmo82sS1p/dnrty6p4/DfMbIWZvVjVa6Tt9kvP88BatpljZp+bWdN0vzzXycy6mdnfUjnL3x8za5/KOzc9doGZTTezG8ys4drKVIk7gG8AR1UoV0PgVOBp4KW1lP+bZvYHM5tnZl+Y2fvp/jer2L65md1pZh+a2TIzm2Fmp66tgGbW1Mx+md6rZWb2Wfr8DqvhvorUeQq8RIrMzJoD3wVedfengbvTqsFVbN8FmAkMA94HbiSCtUXA8PXd9mvYHXgOaJmeewTwv7RuENAP+A+xX7cBHwAXAk+Z2VYVymtmdg8wBmgPPABcD0wGevJl8PHH9Bpnmln9Ssp0OtAAuH1tBXf3Z1LZjjKzbSuuN7NuQGvgL+7+cYXV+6VyNQLuImorvzCz9un9OAZ4FrgO+DOwADgX2HRtZarEaGAJUbuV77tAcyIwq5SZdSVqzE4GpgDXpjL1B6bmAtm87bclArnTgVeBG4AZxOd2QRWvsSswDbiU2MfbgLFAG+CfZqZmc5F87q6LLroU8UIcsBz4Ud6yacBqYI8K224CvJW2/34lz7Xz+myb7jswqYoy3pPWt8xb1jItc+AXVTxuV6B+Jctz+WyXVFg+OC1/HmhSYV19oEXe/VvStkdV2M6AN4lgpUll5aqw/Y/S8wytZN1v07qj85b1ytvvsyp5zG/SumMqWbcNUK+a3wsH3ku3f0/kce2Ut/6fwGfA5sDVafuBFd6HOWl5/wrP3TctfyW/PETQ7MD1FbbvAqxI64ZXWDcpfVf7VVi+NRG0LQOa5y0fWLGsuuiyMV1U4yVSRCmp/kziwPWHvFX3EAfOirUcRxMBz8Pu/qeKz+fu767ntl/Hh8AVla1w97fdfVUlq+4iaqwOr7B8WLo+y90/q/Bcq9z9g7xFt+a2rfAcuXy5sRWfowojifd/jea0lGPXD5gP/KOSx81w97XVqC2ruMDdP3H31dUoU0V3EIHn6alsuwKHAqPcfWkVj+lO1NY94+6jKpRjLPAksBfQIz1nQ6Im7Cu1oe4+lajNXIOZdSCS++939zEVHvMpcDlRI9in2nsqUscp8BIproOJprrH3H1e3vI/AV8AAyvkBH0rXVcWCFRUk22/jpnu/nllK8ysoZkNNbMnUx7UKjNzItBpDOyYt+0WQDvgQ3d/YV0v6u4vAf8GjjSznfNW5Zpob6tO4d39PeBxoIuZ7Z236migKRHcVNZr8PkqnnIssAp4MOVSnWJrGQ6immV8DngRON3M6hEBeT3W0swIdErXT1SxPrd8n3Tdmqg9m1FFwDqpkmX7pesmKedtjQsRBEM0O4oIkQMhIsWTCxLuyV/o7gvN7C9ETcExwH1p1dbpOj9Iq0pNtv06/ruWdWOJTgJvAg+lbXNB2vmsme+0dbquSXl/BxxABCKXm9k3iNynGe5eVWBUmXuIGqRTgUvSslwN2L1VPKbS/Xb3582sJ/AT4ARgAICZ/Qe4wt1H16Bc+e4AbgKOAE4Dpq0jQG2Srj+oYn1u+dYVtv+wiu0r299cXtyh6VKVLdeyTmSjohovkSIxs2bAsenuaPtyEExPtUK55pn8JPtP0/WOrFtNtoXIu6nqZGzrdTzuK1Li9nHABKC1u5/m7j9y9+HAlUQO2tcpL0Ty/YfAGSnJvlpJ9ZUYTzR9nmxm9dNncyRRmzezisdUut8QSfvufhSR07U/cBWRCP8nM+tdw7LljCSaL28n3qMR69g+V2v1jSrWt6iwXe66eRXbV/Y8ucf8wN1tLZfT1lFWkY2GAi+R4jmVCD6mAXdWcVkA9DazVukxz6brI6vx/DXZFuATYOeKC1NA07Gaz5Fvj3T9sLuvqLCuG7BZ/gJ3XwLMBpqb2T5UQ3re3xOByNFEzddiKslHWsfzLCN6Hu4A9CZynRpQdW1XdZ/3c3d/2t0vA85Li49Zz+f6lKj53InoOLCumrNcbVivKtbnlk9P168AS4GOZtZkLdvny33Heq6jLCKSKPASKZ5c4vy57n5mZReidiM/yf4vwFzgu2Z2UsUnNLP82qKabAuRs7RLJWMv/ZTonVhTc9N1rwqvuz3RW7AyN6Xr2yse/M2snpm1qOQxI4icqluIpPo/ufui9SjvPen6lHRZSQ0DuFTOnlUELrmapKqS4avjp0Qt4uHV2MeniKEyepjZCRXKeALRRPsqkWSfC2JHAVtR+bAk/Su+QEq6nwwcb2anV1YIMytLn7mIoBwvkaKwGGB0L+DFdeQi3UnkCp1mZpe7+xdmdiLwKNFsdRZR69CISGA+hPS7rsm2ybVEL8OHzGws8DHRM64VkVjdq4a7OYU4+B9vZk8TB/jmRA3cf4hxxSr6PdHL7hTgNTN7iKj124HoiHAXX+1x946Z/Y3I7YKaNzPmnucpM3sdOBFoSIzdNX89nuqHwGEWg9G+SdTAtSX2+xPW3US4tjK+A7xTzW09DXz6GDA2vZevEN+7Y4nei6dU6GX5Y+J7cX4Ktp4kmiT7An/ny/c43/eJRP07zew8YgyzT4maufZEh4n9iN6hIhs91XiJFEduUMnfr20jd59L5Ei1IJrScrUMHYnhFHYlBiMdQORhXV7h8TXZ9nHigPwSMYzCqUStVTfg7ZrtXgz/QByobyUCp/OIoOr3RIBXsfkRD6cSA37OAb6XynwgUbPycBUvd1e6nuru06vYpjruJYKu3O318TuiU0FL4r0eBuyZlu/j7m98jfLVSOoN2ZXoJbsfcDERTI8Guqb1+dt/ROSk3U30cjyf+P6cQwxkW9lrvAd0Jk4QVhE1Y+el13mHGO5jrTMIiGxMzL3K/FARkZKQhi64HDjT3e8scnFERKqkwEtESlqadug1oqZq57UMKCoiUnTK8RKRkmRm3yEGCT2ayB27SEGXiNR2CrxEpFSdSOShfQj8kipykEREahM1NYqIiIhkRL0aRURERDJSEk2N2223nbds2bLYxRARERFZp2nTpn3k7s0qW1cSgVfLli2ZOnVqsYshIiIisk5mVuXYh2pqFBEREcmIAi8RERGRjCjwEhEREclISeR4iYjIxmvFihW89957LF++vNhFEVlDo0aN2GmnnWjYsOG6N04UeImISK323nvvsdVWW9GyZUvMrNjFEQHA3Vm4cCHvvfcerVq1qvbj1NQoIiK12vLly9l2220VdEmtYmZsu+22Na6JVeAlIiK1noIuqY3W53upwEtEREQkIwq8RESkpJht2Et1jR8/HjPjlVdeKdzOFdCkSZNo0qQJ++yzD3vttRcHHHAAf/3rX9f5uM8//5zevXvTsWNHxo4du16ve9RRR5Xffvrpp2v8HHWJkutFRESqYfTo0fTo0YMxY8YwfPjwgrzGqlWrqF+/fkGeG6Bnz57lwdaMGTM49thj2WyzzTjkkEOqfMwLL7zAihUrmDFjxtd+/UmTJrHlllvSvXv3r/1cpUo1XiIiIuuwePFinnrqKe68807GjBkDRJB00UUXUVZWRvv27bn55psBmDJlCt27d6dDhw5069aNRYsWcc899zB06NDy5zvqqKOYNGkSAFtuuSWXXXYZ++67L8888wxXXnklXbt2pV27dgwePBh3B+D111+nd+/edOjQgU6dOvHGG28wYMAAHnroofLn7d+/Pw8//HC19qljx45cdtll3HLLLQAsWLCAPn360LVrV7p27cpTTz3F/PnzOfnkk5kxYwYdO3bkjTfeqLJ8vXr1Kp/e76OPPqLiHMtz587ltttu4/rrr6djx45Mnjy5hp9C3aDAS0REZB0efPBBjjjiCPbcc0+aNm3K9OnTGTFiBG+99RYvvPACs2bNon///nzxxRf07duXG2+8kZkzZzJhwgQ222yztT73kiVLaNeuHc899xw9evRg6NChTJkyhdmzZ7Ns2bLyGqr+/fszZMgQZs6cydNPP02LFi0488wzufvuuwH47LPPePrpp/n2t79d7f3q1KlTedPpD37wAy644AKmTJnC/fffz5lnnsn222/P73//e3r27MmMGTPYfffdqyzfurRs2ZKzzz6bCy64gBkzZtCzZ89ql7MuUVOjiIjIOowePZrzzz8fgH79+jF69GjefPNNzj77bBo0iENp06ZNefHFF2nRogVdu3YFoHHjxut87vr169OnT5/y+xMnTuSaa65h6dKlfPzxx7Rt25ZevXoxb948jjvuOCAG7gQ48MADGTJkCPPnz+eBBx6gT58+5eWpjlxtFcCECRN4+eWXy+//73//Y9GiRV95TGXlO/roo6v9mhs7BV4iIiJrsXDhQp544glmz56NmbFq1SrMjM6dO39lOAF3r3SIgQYNGrB69ery+/ljPzVq1Kg8r2v58uWce+65TJ06lZ133pnhw4ezfPnyNQKkigYMGMCoUaMYM2YMd911V4327YUXXqBNmzYArF69mmeeeWatNXRVla/iPmqWgaqpqVFERGQt7rvvPk455RTefvtt5s6dy7vvvkurVq3o1KkTt912GytXrgTg448/pnXr1rz//vtMmTIFgEWLFrFy5UpatmzJjBkzWL16Ne+++y7PP/98pa+VC1i22247Fi9ezH333QdEzdlOO+3Egw8+CERPw6VLlwIwcOBAbrjhBgDatm1b7f2aNWsWV111FUOGDAHgsMMOK8/3AipNpq+qfBBNidOmTSt/zyqz1VZbVVqLtjFR4CUiIiXFfcNe1mX06NHlTXw5ffr04f3332eXXXahffv2dOjQgT/96U9ssskmjB07lmHDhtGhQwcOPfRQli9fzv7770+rVq0oKyvjoosuolOnTpW+1tZbb82gQYMoKyvj2GOPLW+yBBg5ciQ33XQT7du3p3v37vz3v/8FoHnz5rRp04bTTjttnfsyefLk8uEkhgwZwk033VTeo/Gmm25i6tSptG/fnr333pvbbrutRuW76KKLuPXWW+nevTsfffRRpa9/9NFHM378+I06ud7WVn1ZW3Tp0sVzPSVERGTjMmfOnPLmMPmqpUuXUlZWxvTp02nSpEmxi7PRqez7aWbT3L1LZdurxktERKRETZgwgdatWzNs2DAFXSVCyfUiIiIlqnfv3rzzzjtrLHvkkUe45JJL1ljWqlUrxo8fn2XRpAoKvEREROqQww8/nMMPP7zYxZAqqKlRREREJCMKvEREREQyosBLREREJCMKvEREREQyouR6EREpKXbFV6fk+Tr88uqNZzl+/HiOP/545syZQ+vWrTdoGbIwadIkrr322jUmtR44cCBHHXUUJ5xwQsFe95577uHiiy9mxx135IsvvuCCCy5g0KBBBXu96rrhhhsYPHgwm2++eaavqxovERGRahg9ejQ9evRgzJgxBXuNVatWFey5iyE3nVLfvn2ZMWMGkyZN4sc//jEffvhhtR5fyPfjhhtuKJ92qbo2RHkUeImIiKzD4sWLeeqpp7jzzjvLA69Vq1Zx0UUXUVZWRvv27bn55psBmDJlCt27d6dDhw5069aNRYsWcc899zB06NDy5zvqqKOYNGkSAFtuuSWXXXYZ++67L8888wxXXnklXbt2pV27dgwePLh8guzXX3+d3r1706FDBzp16sQbb7zBgAEDeOihh8qft3///jz88MM13r/HH398jWmRHnvsMY4//vjy8v3whz+kU6dOHHLIISxYsACAN954gyOOOILOnTvTs2dPXnnlFSBq0S688EIOOuigr4wntv3227P77rvz9ttvc84559ClSxfatm3L5ZdfXr5Ny5YtufLKK+nRowfjxo3jjjvuoGvXrnTo0IE+ffqsMUflOeecw0EHHcRuu+3Gv/71L04//XTatGnDwIEDy5/v0UcfZb/99qNTp06ceOKJLF68mJtuuon333+fgw46iIMOOqjK7Sorz9elwEtERGQdHnzwQY444gj23HNPmjZtyvTp0xkxYgRvvfUWL7zwArNmzaJ///588cUX9O3blxtvvJGZM2cyYcIENttss7U+95IlS2jXrh3PPfccPXr0YOjQoUyZMoXZs2ezbNmy8qbB/v37M2TIEGbOnMnTTz9NixYtOPPMM7n77rsB+Oyzz3j66af59re/XeVrTZ48mY4dO5ZfckHawQcfzJw5c8qDqrvvvrt87sclS5bQqVMnpk+fzoEHHsgVV1wBwODBg7n55puZNm0a1157Leeee27567z66qtMmDCB3/zmN2u8/ptvvsmbb77JHnvswc9//nOmTp3KrFmz+Ne//sWsWbPKt2vUqBFPPvkk/fr14/jjj2fKlCnMnDmTNm3acOedd5Zv98knn/DEE09w/fXXc/TRR3PBBRfw0ksv8eKLLzJjxgw++ugjrr76aiZMmMD06dPp0qUL1113Heeddx477LADEydOZOLEiVVuV1l5vi7leImIiKzD6NGjOf/88wHo168fo0eP5s033+Tss8+mQYM4lDZt2pQXX3yRFi1alE8e3bhx43U+d/369enTp0/5/YkTJ3LNNdewdOlSPv74Y9q2bUuvXr2YN29eea1Uo0aNADjwwAMZMmQI8+fP54EHHqBPnz7l5alMz549v5LjBWBmDBgwgD/+8Y+cdtppPPPMM/zhD38AoF69evTt2xeAk08+meOPP57Fixfz9NNPc+KJJ5Y/1+eff15++8QTT6R+/frl98eOHcuTTz7Jpptuyu23307Tpk257bbbGDFiBCtXruSDDz7g5Zdfpn379gDlrwcwe/ZsfvrTn/Lpp5+yePHiNQaHPfroozEzysrKaN68OWVlZQC0bduWuXPn8t577/Hyyy+z//77A/DFF1+w3377feV9efbZZ9e6XX55vi4FXiIiImuxcOFCnnjiCWbPno2ZsWrVKsyMzp07Y7Zmor+7f2UZQIMGDVi9enX5/eXLl5ffbtSoUXmQsnz5cs4991ymTp3KzjvvzPDhw1m+fHl5c2NlBgwYwKhRoxgzZgx33XXXeu/naaedxtFHH02jRo048cQTqwzgzIzVq1ez9dZbM2PGjEq32WKLLda437dvX2655Zby+2+99RbXXnstU6ZMYZtttmHgwIFrvCf5jx84cCAPPvggHTp04J577ilvogXYdNNNgQgOc7dz91euXEn9+vU59NBDGT169Fr33d3Xul3F/fk61NQoIiKyFvfddx+nnHIKb7/9NnPnzuXdd9+lVatWdOrUidtuu608gfzjjz+mdevWvP/++0yZMgWARYsWsXLlSlq2bMmMGTNYvXo17777Ls8//3ylr5ULPrbbbjsWL17MfffdB0TN2U477cSDDz4IRO1Sfq7TDTfcAERNz/raYYcd2GGHHbj66qvXyJFavXp1eTn+9Kc/0aNHDxo3bkyrVq3Kc57cnZkzZ1b7tf73v/+xxRZb0KRJEz788EP+8Y9/VLntokWLaNGiBStWrGDUqFE12qdvfetbPPXUU7z++usALF26lFdffRWArbbaikWLFq1zuw1NNV4iIlJSqjv8w4YyevRoLr300jWW9enThzlz5rDLLrvQvn17GjZsyKBBgxg6dChjx45l2LBhLFu2jM0224wJEyaw//7706pVK8rKymjXrh2dOnWq9LW23nprBg0aRFlZGS1btixvsgQYOXIkZ511FpdddhkNGzZk3Lhx7LbbbjRv3pw2bdpw7LHHfu197d+/PwsWLGDvvfcuX7bFFlvw0ksv0blzZ5o0acLYsWMBGDVqFOeccw5XX301K1asoF+/fnTo0KFar9OhQwf22Wcf2rZty2677VbexFeZq666in333Zddd92VsrKy8mCpOpo1a8Y999zDSSedVN4UevXVV7PnnnsyePBgjjzySFq0aMHEiROr3G5Ds7VVX9YWXbp08alTpxa7GCIiUgRz5syhTZs2xS5GrbV06VLKysqYPn06TZo0+VrPNXToUPbZZx/OOOOM8mVbbrlleQ8/+arKvp9mNs3du1S2vZoaRUREStSECRNo3bo1w4YN+9pBV+fOnZk1axYnn3zyBiqdVEZNjSIiIiWqd+/evPPOO2sse+SRR74yflarVq0YP378Wp9r2rRplS5XbdeGpcBLRESkDjn88MPXGHJBahc1NYqIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImISGkx27CXaho/fjxmxiuvvFLAnSucSZMm0aRJkzUmyZ4wYcJaH9OrVy9qwziaAwcOLB89v9SpV6OIiEg1jB49mh49ejBmzBiGDx9ekNdYtWrVGpNLb2gVJ8mW7KnGS0REZB0WL17MU089xZ133smYMWOACJIuuugiysrKaN++PTfffDMAU6ZMoXv37nTo0IFu3bqxaNEi7rnnHoYOHVr+fEcddVT5ZM9bbrkll112Gfvuuy/PPPMMV155JV27dqVdu3YMHjy4fILs119/nd69e9OhQwc6derEG2+8wYABA3jooYfKn7d///48/PDDNdq3uXPn0qZNGwYNGkTbtm057LDDWLZsWfn6cePG0a1bN/bcc08mT55c/piePXvSqVMnOnXqxNNPPw1ErVqvXr044YQTaN26Nf379y8vf2Xvy6pVq7j44ovp2rUr7du35/bbbwdi7sehQ4ey9957853vfIf58+fXaJ9qNXev9ZfOnTu7iIhsnF5++eU1F8CGvVTDyJEj/fTTT3d39/3228+nTZvmv/vd7/z444/3FStWuLv7woUL/fPPP/dWrVr5888/7+7un332ma9YscLvvvtuHzJkSPnzfec73/GJEyem3cHHjh1bvm7hwoXlt08++WR/+OGH3d29W7du/sADD7i7+7Jly3zJkiU+adIkP+aYY9zd/dNPP/WWLVuWl6eiiRMneuPGjb1Dhw7ll9dff93feustr1+/vr/wwgvu7n7iiSf6yJEj3d39wAMP9AsvvNDd3f/2t7/5IYcc4u7uS5Ys8WXLlrm7+6uvvuq543TuNd59911ftWqVf+tb3/LJkydX+b7cfvvtftVVV7m7+/Lly71z587+5ptv+v333++9e/f2lStX+rx587xJkyY+bty4an1WWfvK99PdgaleRUyjpkYREZF1GD16NOeffz4A/fr1Y/To0bz55pucffbZNGgQh9KmTZvy4osv0qJFi/LJrRs3brzO565fvz59+vQpvz9x4kSuueYali5dyscff0zbtm3p1asX8+bN47jjjgOgUaNGABx44IEMGTKE+fPn88ADD9CnT5/y8lSmsqbGuXPn0qpVKzp27AjE1EFz584tX3/88cd/ZfmKFSsYOnQoM2bMoH79+rz66qvl23fr1o2ddtoJgI4dOzJ37lyaNGlS6fvy6KOPMmvWrPL8rc8++4zXXnuNf//735x00knUr1+fHXbYgYMPPnid72OpUOAlIiKyFgsXLuSJJ55g9uzZmBmrVq3CzOjcuTNWITnf3b+yDKBBgwasXr26/P7y5cvLbzdq1Kg8r2v58uWce+65TJ06lZ133pnhw4ezfPny8ua6ygwYMIBRo0YxZswY7rrrrvXax0033bT8dv369ddoasytq1+/PitXrgTg+uuvp3nz5sycOZPVq1eXB4KVPdfKlSurfF/cnZtvvvkrI+3//e9/r3T7ukA5XiIiImtx3333ccopp/D2228zd+5c3n33XVq1akWnTp247bbbyoORjz/+mNatW/P+++8zZcoUABYtWsTKlStp2bIlM2bMYPXq1bz77rs8//zzlb5WLiDbbrvtWLx4cXlNUOPGjdlpp5148MEHAfj8889ZunQpED3+brjhBgDatm1bqLdhDZ999hktWrSgXr16jBw5klWrVq11+6rel8MPP5xbb72VFStWAPDqq6+yZMkSDjjgAMaMGcOqVav44IMPmDhxYsH3KSuq8RIRkdKyltqfQhg9ejSXXnrpGsv69OnDnDlz2GWXXWjfvj0NGzZk0KBBDB06lLFjxzJs2DCWLVvGZpttxoQJE9h///1p1aoVZWVltGvXjk6dOlX6WltvvTWDBg2irKyMli1bljfNAYwcOZKzzjqLyy67jIYNGzJu3Dh22203mjdvTps2bTj22GPXuS+TJ08ub1IE+OlPf0qXLl1q/J6ce+659OnTh3HjxnHQQQexxRZbrHX7TTbZpNL35cwzz2Tu3Ll06tQJd6dZs2Y8+OCDHHfccTzxxBOUlZWx5557cuCBB9a4jLWVra36srbo0qWL14ZxREREJHtz5syhTZs2xS5GrbV06VLKysqYPn06TZo0KXZxNjqVfT/NbJq7VxrRqqlRRESkRE2YMIHWrVszbNgwBV0lQk2NIiIiJap379688847ayx75JFHuOSSS9ZY1qpVK8aPH59l0aQKCrxERETqkMMPP/wrvQSl9lBTo4iI1HqlkI8sG5/1+V4q8BIRkVqtUaNGLFy4UMGX1CruzsKFC9cYw6w61NQoIiK12k477cR7773HggULil0UkTU0atSofJT+6lLgJSIitVrDhg1p1apVsYshskGoqVFEREQkIwq8RERERDKiwEtEREQkIwq8RERERDKiwEtEREQkIwq8RERERDKiwEtEREQkIwq8RERERDKiwEtEREQkIwq8RERERDKiwEtEREQkIwUNvMzsB2Y228xeMrPz07KmZvaYmb2WrrcpZBlEREREaouCBV5m1g4YBHQDOgBHmdk3gUuBx939m8Dj6b6IiIhInVfIGq82wLPuvtTdVwL/Ao4DjgHuTdvcCxxbwDKIiIiI1BqFDLxmAweY2bZmtjnwbWBnoLm7fwCQrrev7MFmNtjMpprZ1AULFhSwmCIiIiLZKFjg5e5zgP8DHgP+CcwEVtbg8SPcvYu7d2nWrFmBSikiIiKSnYIm17v7ne7eyd0PAD4GXgM+NLMWAOl6fiHLICIiIlJbFLpX4/bpehfgeGA08DBwatrkVOChQpZBREREpLZoUODnv9/MtgVWAEPc/RMz+xXwZzM7A3gHOLHAZRARERGpFQoaeLl7z0qWLQQOKeTrioiIiNRGGrleREREJCMKvEREREQyosBLREREJCMKvEREREQyosBLREREJCMKvEREREQyosBLREREJCMKvEREREQyosBLREREJCMKvEREREQyosBLREREJCMKvEREREQyosBLREREJCMKvEREREQyosBLREREJCMKvEREREQyosBLREREJCMKvEREREQyosBLREREJCMKvEREREQy0qDYBRApaWY12969MOUQEZGSoBovERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJSINiF0BqP7vCarS9X+4FKolsSDX+XIfX8AW8hL8HVrP3pqT3VUQypRovERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJiAIvERERkYwo8BIRERHJSINiF2CjYVaz7d0LU46NTE3fdobX7AH6lEqDXVG6n6v+OgTW4zt8ub4ItZVqvEREREQyosBLREREJCMFDbzM7AIze8nMZpvZaDNrZGbDzWyemc1Il28XsgwiIiIitUXBcrzMbEfgPGBvd19mZn8G+qXV17v7tYV6bREREZHaqNBNjQ2AzcysAbA58H6BX09ERESk1ipY4OXu84BrgXeAD4DP3P3RtHqomc0ys7vMbJtClUFERESkNilY4JUCqmOAVsAOwBZmdjJwK7A70JEIyH5TxeMHm9lUM5u6YMGCQhVTREREJDOFbGrsDbzl7gvcfQXwANDd3T9091Xuvhq4A+hW2YPdfYS7d3H3Ls2aNStgMUVERESyUcjA6x3gW2a2uZkZcAgwx8xa5G1zHDC7gGUQERERqTUK1qvR3Z8zs/uA6cBK4AVgBPB7M+tIDA49FzirUGUQERERqU0KOmWQu18OXF5h8YBCvqaIiIhIbaWR60VEREQyosBLREREJCMKvEREREQyosBLREREJCMKvEREREQyosBLREREJCMFHU5CRESyZVdYjbb3y71AJSm8Gu/r8Bq+gJfue4PV7L0p6X0tMarxEhEREcmIAi8RERGRjCjwEhEREcmIAi8RERGRjCjwEhEREcmIAi8RERGRjCjwEhEREcmIAi8RERGRjCjwEhEREcmIAi8RERGRjCjwEhEREcmIAi8RERGRjCjwEhEREcmIAi8RERGRjCjwEhEREcmIAi8RERGRjCjwEhEREcmIAi8RERGRjDQodgFERKSIzGq2vXthykHNi8LwQpQiGxvTvtaUXVGzN8cvL9x3shBU4yUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4LURMqvZRUREpNYqsYOaAi8RERGRjCjwEhEREcnIOgMvMzvKzBSgiYiIiHxN1Qmo+gGvmdk1Ztam0AUSERERqavWGXi5+8nAPsAbwN1m9oyZDTazrQpeOhEREZE6pFpNiO7+P+B+YAzQAjgOmG5mwwpYNhEREZE6pTo5Xkeb2XjgCaAh0M3djwQ6ABcVuHwiIiIidUaDamxzInC9u/87f6G7LzWz0wtTLBEREZG6pzqB1+XAB7k7ZrYZ0Nzd57r74wUrmYiIiEgdU50cr3HA6rz7q9IyEREREamB6gReDdz9i9yddHuTwhVJREREpG6qTuC1wMy+m7tjZscAHxWuSCIiIiJ1U3VyvM4GRpnZLYAB7wKnFLRUIiIiInXQOgMvd38D+JaZbQmYuy8qfLFERERE6p7q1HhhZt8B2gKNzAwAd7+ygOUSERERqXOqM4DqbUBfYBjR1HgisGuByyUiIiJS51Qnub67u58CfOLuVwD7ATsXtlgiIiIidU91Aq/l6Xqpme0ArABaFa5IIiIiInVTdXK8/mJmWwO/BqYDDtxRyEKVArvCarS9F6gcIiIiUjrWGniZWT3gcXf/FLjfzP4KNHL3z6rz5GZ2AXAmEXe8CJwGbA6MBVoCc4Hvufsn61l+ERERkZKx1qZGd18N/Cbv/uc1CLp2BM4Durh7O6A+0A+4lAjmvgk8nu6LiIiI1HnVyfF61Mz6WG4ciZppAGxmZg2Imq73gWOAe9P6e4Fj1+N5RUREREpOdXK8LgS2AFaa2XJiSAl398Zre5C7zzOza4F3gGXAo+7+qJk1d/cP0jYfmNn2lT3ezAYDgwF22WWXau+QiIiISG21zhovd9/K3eu5+ybu3jjdX2vQBWBm2xC1W62AHYAtzOzk6hbM3Ue4exd379KsWbPqPkxERESk1lpnjZeZHVDZcnf/9zoe2ht4y90XpOd5AOgOfGhmLVJtVwtgfg3LLCIiIlKSqtPUeHHe7UZAN2AacPA6HvcOMcfj5kRT4yHAVGAJcCrwq3T9UA3LLCIiIlKSqjNJ9tH5981sZ+CaajzuOTO7jxj7ayXwAjAC2BL4s5mdQQRnJ65HuUVERERKTrUmya7gPaBddTZ098uByyss/pyo/RIRERHZqFQnx+tmvhx4vR7QEZhZwDKJiIiI1EnVqfGamnd7JTDa3Z8qUHlERERE6qzqBF73AcvdfRWAmdU3s83dfWlhiyYiIiJSt1Rn5PrHgc3y7m8GTChMcURERETqruoEXo3cfXHuTrq9eeGKJCIiIlI3VSfwWmJmnXJ3zKwzMS6XiIiIiNRAdXK8zgfGmdn76X4LoG/BSiQiIiJSR1VnANUpZtYa2IuYIPsVd19R8JKJiIiI1DHrbGo0syHAFu4+291fBLY0s3MLXzQRERGRuqU6OV6D3P3T3B13/wQYVLASiYiIiNRR1Qm86pmZ5e6YWX1gk8IVqTjManYRqW02pu/wxrSvIlK3VCe5/hFiUuvbiKmDzgb+UdBSiYiIiNRB1Qm8LgEGA+cQyfUvED0bRURERKQG1tnU6O6rgWeBN4EuwCHAnAKXS0RERKTOqbLGy8z2BPoBJwELgbEA7n5QNkUTERERqVvW1tT4CjAZONrdXwcwswsyKZWIiIhIHbS2psY+wH+BiWZ2h5kdQuR4iYiIiMh6qDLwcvfx7t4XaA1MAi4AmpvZrWZ2WEblExEREakzqpNcv8TdR7n7UcBOwAzg0kIXTERERKSuqc4AquXc/WN3v93dDy5UgURERETqqhoFXiIiIiKy/hR4iYiIiGREgZeIiIhIRhR4iYiIiGREgZeIiIhIRhR4iYiIiGREgZeIiIhIRhR4iYiIiGREgZeIiIhIRhoUuwBSB1kN51J3L0w5REREahnVeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkRIGXiIiISEYUeImIiIhkpEGhntjM9gLG5i3aDbgM2BoYBCxIy3/s7n8vVDlEREREaouCBV7u/h+gI4CZ1QfmAeOB04Dr3f3aQr22iIiISG2UVVPjIcAb7v52Rq8nIiIiUutkFXj1A0bn3R9qZrPM7C4z2yajMoiIiIgUVcEDLzPbBPguMC4tuhXYnWiG/AD4TRWPG2xmU81s6oIFCyrbRERERKSkZFHjdSQw3d0/BHD3D919lbuvBu4AulX2IHcf4e5d3L1Ls2bNMiimiIiISGFlEXidRF4zo5m1yFt3HDA7gzKIiIiIFF3BejUCmNnmwKHAWXmLrzGzjoADcyusExEREamzChp4uftSYNsKywYU8jVFREREaiuNXC8iIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiIhlR4CUiIiKSEQVeIiIiUjBmNbvUdQq8RERERDKiwEtEREQkIwq8RERERDKiwEtEREQkIwq8RERERDKiwEtEREQkIwq8RERERDKiwEtEREQkIwq8RERERDKiwEtEREQkIwq8RERERDKiwEtEREQkIwULvMxsLzObkXf5n5mdb2ZNzewxM3stXW9TqDKIiIiI1CYFC7zc/T/u3tHdOwKdgaXAeOBS4HF3/ybweLovIiIiUudl1dR4CPCGu78NHAPcm5bfCxybURlEREREiiqrwKsfMDrdbu7uHwCk6+0re4CZDTazqWY2dcGCBRkVU0RERKRwCh54mdkmwHeBcTV5nLuPcPcu7t6lWbNmhSmciIiISIayqPE6Epju7h+m+x+aWQuAdD0/gzKIiIiIFF0WgddJfNnMCPAwcGq6fSrwUAZlEBERESm6ggZeZrY5cCjwQN7iXwGHmtlrad2vClkGERERkdqiQSGf3N2XAttWWLaQ6OUoIiIislHRyPUiIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGVHgJSIiIpIRBV4iIiIiGSlo4GVmW5vZfWb2ipnNMbP9zGy4mc0zsxnp8u1ClkFERESktmhQ4Oe/Efinu59gZpsAmwOHA9e7+7UFfm0RERGRWqVggZeZNQYOAAYCuPsXwBdmVqiXFBEREanVCtnUuBuwALjbzF4ws9+b2RZp3VAzm2Vmd5nZNgUsg4iIiEitYe5emCc26wI8C+zv7s+Z2Y3A/4BbgI8AB64CWrj76ZU8fjAwON3dC/hPQQq6btsR5d0YaF/rJu1r3aR9rZu0r3XDru7erLIVhQy8vgE86+4t0/2ewKXu/p28bVoCf3X3dgUpxAZgZlPdvUuxy5EF7WvdpH2tm7SvdZP2te4rWFOju/8XeNfM9kqLDgFeNrMWeZsdB8wuVBlEREREapNC92ocBoxKPRrfBE4DbjKzjkRT41zgrAKXQURERKRWKGjg5e4zgIrViAMK+ZoFMKLYBciQ9rVu0r7WTdrXukn7WscVLMdLRERERNakKYNEREREMqLAS6TAzKxRscsga2ca2Vk2Avqe1w4KvIrIzOoXuwyFYmb6bgFmti3wfTPbNN1vWdwS1Uzuc6zLf9hmdjZws5ltX+yyFJKZ7VDX97EqZtbUzM7eiPe/HoDX8twiMxtmZv3TcFR1lg6OReTuqwDM7Agz266uHNzMrJ67r063m+eCjo1JXlC9CNgJmGRmk4E2xStV9ZlZAzPrDmyWFtXJkwQz2ww4DOgN7FtXT4bMbEuio9NJZnZwOrhtFDWxKej4IfA7oKeZNSxykTKX93+8r5n9yswKPaJBjaRj4AtAL2AhsENxS1RYterN39iYWTfgF8CnxOThXwCXFLNMG4K7rzaz7YhJ0lcDlxPDidR5KXi2XFBN7H9HYBfgJ+7+j2KVrSbcfaWZHQkcZmY7E6NLl/x3E8DMdgKWuPsn7r7MzD4AWgCtie/pS0Ut4AZkZvXdfZW7LzazJsBPiQPb9919eZGLV1Bmtom7f5H+jz4BZhGzoOwNzCxu6Qov99mn242Aq4HNgSfcfWVRC5fHzLYGzgF+5u5/LXJxMqEar4xUcSbdE7iMmEh8V+BbpXgWWnHfzKw5MB6Y7u4D3H2jCLogqvLTH/2eZvYIEVBfQBzwDqzNtZqVNA+/DPwYaAhcmX2JNpzc+57GEHwHGGFmB6TVDxPBSBugs5ltXpRCFoC7rzKzTdNJ3gvp8jd3nw51MyXAzLZKv73b0+cNMBlYScwh3MnMtipW+Qot93+cF3Q1IU7qDwa+4e73Fbtm18IVqel3T2CVu//VzBrmpTfUue9mTp3dsdom70dwoJnVT1/8I4GTgSeAWe5+YKmdhZqZ5e3brmnx58CLwCIzO8TMzjCzPkUrZIFVEngeQRzMHwT+6e5vA08CmwCnpG1qXXNHXnPEYWb2A6L25zbgXeDzEv8jbJyuPyT2aTvgGjNrRQzm/CfgaeAAokakTjCzc4j9OtPdZwMXAQ3M7HT48jOvC/JOajYnamg7EQN2NwfmAXcTtZndgbZFKWQGKhxrHgfuTZ/z/yOCzq1TQF7M33NDoEO6QPrNufuK3HeyLn03KyrlP9JaL78dPeVUPEMceG8ByoCHgL7u3s3dh6ftBpnZLsUo7/pwdzezNmY2AbjOzC4hzmAmETMVfIs4mJ1hZt8tXkk3vNwffV6zYs5exATwE4A9zewQ4AOiFnCAmf0Q+EVtSPTNr4EzsyZmdjdR9tfd/TmiRrY78O38P8LaXHOXz8x6pO/mbWZ2irt/APyF+H6+DRxK/CaPAu4CFgM9zKzSyW1rq1SDUK/Csj2Jqdq+6+6D0+L/ECdF3cxsSzPbycx2zLi4G5yZnQvcamb7A/OBO4j/18+JQbtPBfYBfg98BhxQG35/G0KF37Cl3/FDwNnA34Ejzay3u08AHgF+njbPNNG+Qk1yQ2ApEYPMAl40s9xJ6SZ5tV696srnlE+B1wZmZt9KB9Zcnszu6YtTBnyHSPA8gPijvxv4xMzOMrPvmtmjRKLvF0Uq/jpVUruzPXAxkT9wNjFN1IHA/e6+n7v/HLgQ+C/wasbFLYi8gMvT/QPN7F9mdnlqvpoOnEQE2IOAPwJnEoHYP4D9gT+4+/xilD+VOdcckf/n2xJo5u77Av8ws23d/VPgTqC/mbU1sx+Z2VYl0DtqCzP7M/Br4jf3VyJfrRUwgzj4/hd4ish1PQDYGbifCFb2quRpa628Ju7mZtYpLd4c2J347H5sZuOAPkSz24fE9/QeoOTSG3LM7HAzm0h8fvOAc4EeRA7XfL4MNFsQJ4IdgD8A+xInhSXNIo+r/LeYbm8OLAdOd/ffELmZv0yb/B/Qy8y6Z/UbNrNdzGw4UcO8aSrnEuL31y+18jwC9DOzbfLy8sqAY6iDHXuUXL+BWCST/5xIpL7cIlfrXKArceA9mIjyewK/cfe70uMGEIHK0cBIdx+ZfemrL68au6m7f5wWf070mLqCOHDdlKqyt+PLs81JwOvZl3jDsjV7bBrRG+4SIrhsDfyT+JM/BVjk7ivM7HmgZwpifpMuRZX3OX4faE40i34CrDKzacBzRG3dcnc/ysx2IwLJhUSuTG23HdGb9E53fyCV/2TgU3f/xMyeJJo3WgBDiQP3Z+4+2cwauPuTRSv5ejKzS4H+wJx0gDuFONDuQQQfy4gTo2OInL0Z7j6+SMX92iyGavkp8J67n5SWjQQ+SJ/xs0Te3ubEieH/iM9/tplNIoKykpb3O74UeJ8Ipr8AtgLqpe/yDWZ2iZkNc/ebzWw08E2iCbpg0sndFUSFw8PE7/FuM/thqnm+HxhqZo2BsURQ/KCZjSFynr9N/H4/KGQ5i0FTBm0AZvb/iD/vT4AT3f3VdBb2FjDM3Zek2qzV7n5EekxD4uzzAXf/wsysttYiVAg2Dif9aRPB1HTibKoxsa9z0nb7AAuAY4GJ7l5neooBmNlPiKr6d4gmq7bEGfVf3P3qtM3uxIGwD3Cdu99brM+54uumav+7gSZELte2xB/hBOJg9Q6wiuiZeimR57VlXrBd65jZ94B2RPL4cxZ5hX2J7+kgImB8Efivu//YzM4i/uyvdPf/FqnYNZaaYbzC59mUaCq9wN3fMrPrgHbufljeNgcQgcpgd5+bcbE3iPS/+V3gxfQ/ewxwAtEkfjpwHnAv8FoKMs4EOgNXuPt/La+nXykys67AK8DiXJoHcUI0m6jJHEH0oP4HcJu7j0qPGwl0dPeyjMrZjGjW/ZD4fb1nZlsQTcCfACOJQPgqIt1mZXrc94hUlW2BX7j7gizKmzU1NX4NFknyPyFqe04mmi3apdXTibPpLdMf5c1ACzPrbGZ9gSlEDckazVa1Raoe7gTlw0PUM7P2RLffE4ianeuB7Ykzx+eBRqmp469EIPqRu99SykGXfTVvpoOZ/YLoHfQLotbkL0Ar4HvufrWZ7ZhqHLoSNS9HuPu9UJzPuWJzRLIbsI27H+Hu5xJnnIcCLdz9KaIjwM+IM+f5qfq/VgZd6TN5nAh8XwR2S5/bM0Qeyc+IJo2uRG3jd9N3ewJRC31gcUq+ftx9dTrotk2pDA2Ig9UWKegyd78QaGlm3c2slZk9Rhzkhpdw0HUW8G+iU9LRqabkGeJAPotoMm0N3AcMNLODiTwviO/GGvmYuZSBUpA+6weIk6VbiP9XiADlZuBXRBP5e0SN11XEwM3XmdnfiE4FS1ILSy4XrJD735g4URucgq6mqXnxYqIZ+C7iRKgreR0d3P3P7n61u19QV4MuUFPj15Ka025y90UQPw7gcDObDlwHjAL2dPcPgb+kGpDvA+2BH7r748Uqe1XSGeXlRE3V6ekAdiURQNxDBFh9ge8RTaaTzextImftSqI6+U/u/uvsS79hpWr63JlY7kx5TyIP74G02S1Ek/Jd7v62mbUjPvubgLHuPqYIRV9DXnPEucAKombrQ6Cxme3j7i8QZ8zHAlub2d5Ez7/H3f2c4pS6Ri4GHnb3Gyssf9/M7iEOTl8AuPtLZvYUEVDOIM6q38qwrDVmZo08r7dzqq38NZG2MAOo7+79zWw3M+vp7pPTpo8RB7f3id/qPzMu+gZjZj8lmvXPcPeXzWyL1JKwCBhD5NCOSM1SH5jZ34Eu7v6EmY0F3qj4nLXtZLcqFuPp3U/kid5HNBUPTE2G+xFNyp8CD+b9Xh81sznEb/px4ruwO3HCn8W+LwY+M7MfE7+1LdLx8XHi/7EZMajt5sTxsM6Pq7YGd9fla16Aeul6C6J6dUi6f1G6v32xy1jN/TiNaB59Od3fkvjB/xrYFDieOEDfRtSWQARkO6bb2xNn3UXfl6/xHjQFOufd35Y4O/stMCgtG04EmTuk+xcCo4keRNOAgUXehzKiRg6iVnsHImfrbuIgNYLIvRtCBB65xz0KlKXbWxX7s6jmvnYlEnPrVVh+LtA93b4CuDbdPp8Yy2q3Ype9mvt3MVHLcwHQJi3rQhyAGxK1PI+n9YcTNT+HEwe1KcAuxd6Hr7n/DYjZE/6Q+27mrWsB7J1u/xi4I93ejhii59vFLv/X3Pf66XpLIh2gQ7q/C3A7USvdgugoUpb3uOHE8CG59++E9J2/GWiQUdnrEXmTzxIVEIOI5uDfAlenbXoAHwNHFvu9zvqipsZqqtjklM9TU5xHVepDRFftTkR+TBlwaG2u1jazbc1sFHAc8eNYknJGNidqsLZz98+JP/K5RFLmIjPrDPwtPQ53n5/eg5Jk0Rv1aaJWK9dhYhzRW+qPwMVmdgLxGTcl/jhw9+uAM4BrgG7ufk/mhY/ydkq5hLcQvRJ38MjN2xf4j7ufRvQ8fTItewnY38x+m5qiPiWGvcBTLW5tZGv2rJ1PfBbbpHU7pyaZ04gTBIgxunqY2TxibKc+XssH9TWznmY2m+hdOZzogdc9re4BfOwx5tFyYgDm84CJRL7lkcR+9nX3dzIu+gZh0fsUjxrnVcRQELmaWzOz84icpvvT92E00NTM/kEkck90978XpfBfU9q/ep5qqt19MXAtcEPapBMR1BzmUcP3E+DXqVnx30QHr8fynnJT4BR3H+YZjVjv0Rz+b+AAd+9PtAhcSZwY5HKanwR29hKZzWODKnbkVwoX8s6mid6JXUk1AqSzkgrb/5r4A6xHDB2wY7H3oRr72C3v9m+I4Q4gmhAfI9UQEH/qNxDJm9OI3Jmil/9r7vsexJnZ/eTVhBBV8/cCm6f7BxE5RA2JHIubgNa1oPxG/Pn+h0ichmgWviXd7kEEW7layp5EDcJ2xNnzCcDJxd6Pdezf1kRTUsV1uxJn0aen+w1JNZbEScHQdLs/cHix96Wa+7tJ+jwn5C27Hrgo3d6N6F26Zd72I/myBvYr/0mldCFq8e5P383eRHPZ1cAP8rY5iwi4/wj8Oi0bQgRgLfK/O8Xenxrsd8Va228SNVuHpPvPEKkez6b/4IeIk+FvEsekwUQ+adH3pbL9Sv+nk4Czi12mYl+U41UNHjVaTYkmpX5ErUgDYr6z/GTNXO+/+4kcqG09EpVrPXd/HsoTTn9D5KT19JjG4UAiqf5ij7OTf5jZXu5e8t2xk0+JIPnn7v5mqq1sT3SQaEmM9N3Q3Sea2WdEjtcTRI3gZ8Up8pfc3c1sE+Apdx+RFq8E3raYTeAdonbgVOIPeybRRLHKo0akVteKePxrf2pmx5jZTHf/bfo8VhC1ka8Q021NdfdZwLTUueEdooYWT727aquUt/UDYl8eIQbb3dLMLiCG++hH7Fcroun0VmCMmV1L5Pw0JYIxvAR77aX/nVxHo+VmlhuD65/E/jYHysyss7tPc/fb0+P+DuyVHj/C3X+bln+l52dtZjG4dHOi1x9mdjzRA/WPpLwsYuT5PwF7eLRAYGa3EM2sV+f99vNzUovKouNHh/Q9bkecDP6+yMUqOjU1VsK+OkjoPkT19RbuvgfRXLOHmfXP396/nOrgWXe/0GthrwyL3olVNnt6eJ8YNPPytHg00Xx6UN52dSLoSsHyR0SNwaVm9nti3zdPB/GPiTybxim4mQe85O4vu/s1XqQxZir5HH8N7Gxmv7YYo6gVcTAeSTRX/ZMYM+cqvhwGZGltbgKHr/Q8Ow64Ih1UVuR1fvgLEWTdbWb9UpPxZKK7+qPZl7pmUrPZk8QArvWJGtjXiKbgoURNVguiludDIhD5GVHjcWZ6mu/lDsalxMw2N7M90v/Oar7s8PUOcVIz0t1nEJ/nfGLGh85mtoOZ3Uzk8v0zPX5Fes56nnp+Zr9HNZeOHzOBuyx6akL0lr7X3a9z9/8BeHSamMKX/8sQlQFnu/sb6bmqmk2jKNLv879EHuK+CrqSYle51bYLazYr5je/3UU0z2yR7h8HzMxbX+urtCvsWwug0Vq23Zw4WJ+V7g8gzrSKvh8b6j2o+LkRQyr8HWiSt2w3IhAbRySo3kAcHIv2eZPXlER0aNg63T6eqDHpn7f+JuD/0u19iB5Qta45osL+7ZErc7rfhRgjDmIE+t+l2w0qPG4IUUswCmhf7P2o5r72Jmq42lSybkcit+cHectOTJ9pbgzGTYq9D19j37cgxoi7Kd3/f+l3dkK6fxgxOGpu+wbp93cXEYBcBzQs9n6s575vAvTiy5SVbdJnOzbdv5sIpgE2zXvc7sAiIjcq//nqFbrMumzAz7/YBagNl/Rlzu/J1oVIVJ2cDrp90gF4ItA2b7sJxMCYRd+Hdexf/oF6G6IWZEL6A2+5lscdl/a5pHNG8van0j8nvuw9dHg6sO+SgqtcbkIDIqF19yKWfVPycgWJwPg24F9EHsjuafmfiVyPTdP9Y4BRxX7vq7mP3yByuTYjajd6p+XDgfPS7R2Jmqzc/pZ/TqVwIZrTGhE9S7dN/y+5k5vc921XvszVOzxt247IX/sb8Kti78cGeA9ygeOhRCek0cTUTn2J2r6D0/pJwGXp9h55z7Ft3u2S+39K34EziBzSG4mau32JYWo6Eye6DxMdmyCaIQek22XFKrcuG+ay0Tc1plyQnsQffc6JwJ/dvSfxQ7gMWEIc5AbmVQefR+T61Eq5npj+5ThO2xO5Ic+4e2/ijOtCi+lUvsJjOpFDvJZUW6+v/KZgM9sjNccdn1vvX/YeeoSoFj+VqEnINR2vdPfpnqrzi2Q4cKWZbWUxAvStwBvufiCRj3ZZ6oX5a6LmaxczO5sYWPFRqL0DRloMRHw18fvq5e7LiJqr4WmTHmkd7j6PCDh/l9at9rzJu2s7D8uJ2QEaEGNsbZPWrTaz04ngapCZnZ2+k28Tw0dMASa5+6XFKf3Xl5qJ3d3dzJq4+2PEUAn7EDmWY4k8p5Mspl07h3gv/g5ca2bbpKbEhbnm9lL5f8pPYUnfgZbESX1Td/8dUaP+KHChx9Rx84GbzOwOIq94q/TYFzMuumxgG23glXcw/tyj+/+uFtMVQJyFTUvr/0bkkJxD1BAdQfQgwSPP568ZF71abM1pfrpYzE2X6yDwuJlNIP70mwHdK+a15ZTSQa2i/MAzddHelThgrwZ+bGYnmNlmadtcbsn1RMeI9sUoc0UWA9pCzAO6E5EnsYRIqB1nMUvAUuIM+nh3n0JMRv4v4nv8PS/iqPnrYjG1yANED8ve7v4ggEeicKOUPPwyaSiBtO7/ERP9Hlcb96kyZnacmZ1lZptazDHYgMgf/IjIH9w1bfoC0XP6NGBACrIfJ2pGenuJD0ycfoubmdnRwEyLiZDHEr2Fj0ub/ZYIRk/ymILsBGL6m2Pd/ZO8E6JSyuMqDxDNbKCZHUV873/Jl4P7fkEa9NbM+rn7mURHpxeBHik4kzpgowy8LG+MFDPrkBYfRAQgWxG9Ei/Je8i7wHKPKVN+DEzNsrzVZWabWEyTkTt73iQlGt9IzFX2ikfi/GlELsERRE+oQUT1dp2SF3ieRnTDPh8Y7e6XEH/uB5OmeHL3lel78RJR2zKrKIWuwCOJfDfi+9gY+EmqKZhHTFP1b3c/BJgDnJO+z5cRYzj1KYGz49zUIme7+7tm1jgv2DyXqH3cnajtu8XMBplZcyI3qpQmXV9G1DD/nSj7cqLpcCqRp9cbwN1fcPf5RG1I7rN7zt1/6dEJpKRYjEf2nbz7xxOj7Xcjapd/5DFP5kNAezNrk04s/g4ca2bN3P05d384Pb7SE8TayMy2NLMrzGy3VMPXwmJqq+8Tx5MXiLzhRmY2GCDVqj8EDDOz7T16cN7k7h+kmuFaWWstNbPRBF5mtmuuSS0FJV3M7AngohRsPUDUhPQlarbamNnZFoOEnsSXXbX/4u5FH0KgMumMaZiZXWRmPyIOWq8QNXT5gcSORE83iHyLt4lak5KWarUs7/4eZnYJ0VT1/0h5Emn1H9N199REV87dH0rNXZkzs/9LtSON0v1dibJ+QORutSRq5CByhPZOtzcjcmMauvun/uW0MbVd+dQiZvZLYrymf1rMgTqDSKR+nejR9ySRf7mHu08ugaCynLv/091PImqujiS+kx09hpuZQAyy/Fsz29dimqMLiQnXl5RKrU4VGgKTLFI6IAKui939Z0SO085mdizwIPEf2x/A3e8CzvEKPcNLpVkxceL7Ozfdb03kDR/h7hPMbBuil+p4IshsbWanEPMtDnX3+bn/s1yNWYl/FyTZKAKv1Ix0EqlK18x2BH4B/NLdB7j7olTTMY0Y9XdbolZoVyII+4O731GMsq+HZ4gR1JsDd6am0oeJKUVybgE6m9nLRJftwe4+O/OSbkAVckdyZ8V7E80Uc919IjFO0mZmdoxH1/OHiIllW0Pxm1VTE9R3ic8q16TkRJPw6BRonEdMfrsrkZi9g5m9RErWdfdaWRu7FguInmrfJTo1vEg0k+4A/IgIxM4gpkAa4+5neYmMjVcZd/8D8Z8yD7jAzP5AjFd1PlEL9gNgnrsfnH67JSX328urtZwIfIfYL4jR95ul23OIziA/9Bid/VmgocVMGubu75daDY/lzXCSau4WEuOtfZf4Le9HpHpcT5wMDyJy96YQvch3Aaak2rDy9AAFXHWL1eXPM/0JeF6T0/5ErshsIlnxZuLH0IKYguO3ZnYN0SxwjcckrPWKfUCuSgooV6VgozXxp/Y/oolmurtflN6DvYkq7b7u/mp6bCvivZlbnNJvGJY3kXW6/1MiYP6nu99vZpcTPd9uTdX1pxEBSo+0/cHuXis6SKRagb8SvRT7EgemacDRwP8Bb6Um0f8Aj7j7eWa2AzHEyWvFKveGYGabuPsXKYBeZWZnEeNXXW4xXt4/id9oyf9hmVl3IrDuQTQhH0ck1P+c6Nm4oojFW29m9k3gdnc/OAVOnpafQZzQ3kqMVXaNu3dI6wYQc9reUkInt5WyNfNq9ydmtbjTYnL6HkRqwN7E3IsvEj1Wj3H3U9NjtivF5mSpuTpb45VXNbvazNqlxScTB7GVxB9fL6Jb/ifAL81sT6L78jyi2bHotSAVWcxFdySUD06XSwo/GDjU3e8jerUNTvkSq1JNyd+JPz7SY98q5aDLzLaz6Al3WrrfyGKOvj2InkGDzGw4sc/fBPZJZ88jgVUWya3UoqCrnscAmFOJ5rTTgc+JsYzapus90xn1DGA7M2vq7u+XetAF0Uye3oNVZrY7UUP9YVo3yt0X1pGgy4j/n5dSBe2viM/6b+m3WpJBF0D6Hm5rZoenk8FN0qoHiNkhjiOa2t40szvN7EJiOqDxxADNueb1kjwu5Y41ZnYdMcj25RY9yf8ErCCaD2cTE9bvSOx7bhDZeu7+ka1jgGupG0ryC14d6Yf/TTP7G/AzM2vCl2dcvd19pLv3d/ebiNqgx4g/xH+4+4hi5fhUxSKx8kpijsSt07LDiPyJYUST4bMA7v4pMfbPjWm7U4l9vzPzghfOQiI3raOZ7UQMSLiEyAsZRxy4zyNqNCcTeTV7pmD1aK9lvVHzAvxpxKCRi4jR548hupFvSzTJTQcec/fve3T2qBNS7e0+ZvZHonPLH70O9uJKweP2xAlCbtlL7j6teKXaoI4hUhnyg+lPiPy8bxA5XgOIE9w9iNy994na3OXpcbXqZLcqec2quTysxsT/7mvEf+1U4Bfp/3gccEiqoe6V1r/g7qe6+1IvwZ6asv7qTOBlX53mpwkxtcJf3b2vu3/mMQXMi0RX9L0txkS6i8gpedLd36yNX3ozO5xIrm5ATPQ7Oq2aQExnsweRs9Yzd5bp7hcR+RIvEHkF8939T5kXvnA2I4KRbYjaoNXEeGzbAqQ/+wf48oy6PnHWiacpOGqpVcAQM5sNNCGaaP5CBGEPAYd5HZx2wzeuqUWWEpOY19qx1dZXqkX/t5ldlBY1SssfIf7DjicGPx1JTHt0CRF8Tfnqs9Vu/mWif67jwJ7AYne/1d0nETMpdDazfdOJ3ofAMCLoPNTdr4fS6qkpG0ady/FKzS8fW/RUe4gYC+YdM2vkMfnqN4hBJZ8BxgBHAQ95JHfWSma2LzHoab10/2Ci+/kId5+bagv+RtSMzCNy2P5A/NC385gIuWTl54uk+/sTTYb3AvsTNV1nEgnKndz9O2m7PxK5I89WfI7azMxmEdPi3Jbub0sM6FqUeSFlwyql7+L6sBh77F1ipoVlKbA4gRhH8FV3fzxtdzgxE8h1xSvt+jOzQ4nep/OITgRjifk1T3H35yzGCBwHfO7ufVIqy+fu/nZ6fK3NH5bCarDuTWqvCgmchxDJqTMtBgt9jmi22Rl4JwVd5u7/NbPHiGrv5e4+qljlr670Ix5vZuOIP7QDgF+noKu+R8L1LGKfXyf+5LZ397eIyWZLUqoNsEr+nA4Gfu/uvzCzvYnRn89x95+Z2cNmdicxAOprwH9K6UCXguiJpC7o6fNdWNRCyQZVKt/F9eXRKelHwK/NbDwxEv104MzU7JbzaKoJq9Xsyw4f9f3L8R/3IHrcXk20HA0iauF/SjS1diWalGcD+6W8t0fSYy3l9yno2kiVXOCV2si3Iw6qy9Oy/YmefCcRvUbuJoKPZcT4KA2IrrvXmtm/PLp0l5oziDOrke7eJbcw/SFsTjQnjkgJrjOKU8QNJy9YcjNrS+SOPOuRDP8xEXzi7i+bWTfgZDP7h7t/12IQ0a3c/cmi7cB6SkF0PSKxvtTGLRLJuYP4nfYCBuVqufKVQgBqqacmcbKXHyh1B2a6+1/SdnOB3xPpDn3SSXIXYvzAhqQ0ByiN/ZbCKpkcr5Rc/nMir+lKIm/nJ2l1Q+KMqg+R13Wdu/+bGC7iDeLLPwl4vUSDrlzC/K+JHnrlzOwgYsyje4GP6kq+gLu7mTU0s3OIjgHbA3ea2beIs8gP7Mv5Ft8gkuv7WQxLMLMUg64853uMOyZSklJtzu7u3s7dH7dQcv9NXnVPzZnAYbmemMRJ8RtES8opRC7XnsQ4dT3TtQhQIjleKRfgD8QZxXVEcuo+RA+/Y4hxUf6PGJvrUo8JVJsS4xu9a2YtiKTHRUXZgQ3IzN4mhlB4iajZW0EcqN8qasG+por5DhZjWp0K/JAvcyZ+RiTT301MMnwNket1ODHH4v0eo/eLSC1hFcbaKzVm1pLoSfzNdD/X9Hg3MVPEySnV5WLgBHdfnI4/5xM1ZRe6+/NFKr7UQqUSeFVMLs8lyl8AnAh8m5hW5X5gFHFQvh0Y4+43FKfUhWFmfYHRxNyDIzym1ihpFXL19ic6BbxBDIR6CzDZ3f/PYmqne4kAa1Tatiswyd1nFKf0IlLXpbzROe5+rZlt7u5LUw7qI8TQNu2Ay939gbR9faClx9yLImsoicALILWZL3b30/LPoMzsHaJm5FNgIFG92xy41uvW8AnlzOxMYpyj5cUuy/oys63yayAtxuK6nhhYcALQzN3PMbOTiVGfb0r5XAOIz3uwu79ZjLKLyMalkp6aDYnUlnnEGGTv5W1bMp15pDhKKfBqCrwFdHf3l8xsi9R75g9Ebditabs9PU2LI7VPOhO8EjiIGGdrgrvPsJjKZ7W732sxbdNpxBARjxE9hZa7+5XpOb7t7n8vzh6IyMbIYhqrMiK/eATRielMjzEDy5sgi1dCKRUlk1zvMUr3jURvmdwEpBA5P8/kbaegq5ZKuXrziMnKhxODgp6Rzh7/DPzLzP5FDEh4SdpmGZG7t5fFfJQo6BKRIriDmHbuRqLGvU8u6AL1QJbqK6nhJNz9MjM71cx6Af8hRn9eALyl6t2S8CkxvtgVUD5m1RFA/VR7eRAxZMQlZlZG5Hhd7u7DzWyqu/+3aCUXkY2ax1yMu+fG1VvLOIMia1UyNV55/h/wBFHdO87dT/aYDkhBVy3n7s8B91lM0wTwPyK4ynXJ3h34RhqXawDRg3V6eqyCLhEpqrygq4EGQZX1VTI5XvnqQnL5xiovV28kMV3TAmAR8CiRXP9D4DjgEXf/abHKKSIiUgglGXhJabOYQPcqYpy11Wm4kLuI4OvXwKfuvrSYZRQRESkEBV5SFGkg2LPd/R/p/u7ERNBzilsyERGRwlHgJUVhZv2AP7j7JuvcWEREpI4oqV6NUne4+xgz2z6N67VanSNERGRjoBovERERkYyU4nASIiIiIiVJgZeIiIhIRhR4iYiIiGREgZeIiIhIRhR4iYiIiGREgZeIiIhIRhR4iYiIiGREgZeIiIhIRv4/S+JLcZkvgC0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data1 = pd.read_csv('accuracy_default_parameters')\n",
    "data2 = pd.read_csv('accuracy_hyper_parameters')\n",
    "data3 = pd.read_csv('accuracy_data_enhanced')\n",
    "\n",
    "\n",
    "accuracy = pd.concat([data1[['Model',  'Accuracy_Default']], data2['Accuracy_HyperParameter'], data3['Accuracy_Enhanced']], axis=1)\n",
    "\n",
    "data1 = accuracy['Accuracy_Default']\n",
    "data2 = accuracy['Accuracy_HyperParameter']\n",
    "data3 = accuracy['Accuracy_Enhanced']\n",
    "\n",
    "\n",
    "X = np.arange(9)\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "plt.bar(X + 0.0, data1, color = 'b', width = 0.2)\n",
    "plt.bar(X + 0.2, data2, color = 'g', width = 0.2)\n",
    "plt.bar(X + 0.4, data3, color = 'r', width = 0.2)\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vrs Model', fontsize=20)\n",
    "plt.ylim(65, 95)\n",
    "plt.xticks(X, accuracy['Model'], rotation=30)\n",
    "plt.yticks(np.arange(65, 95, 5))\n",
    "plt.legend(labels=['Accuracy_Default', 'Accuracy_HyperParameter', 'Accuracy_Enhanced'])\n",
    "\n",
    "plt.savefig('zor')\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97b91b6d5003af60c654b6abfe8ac1e5d274e52e67a717d7df64331168b10d1c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
